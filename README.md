# Stock Trading Bot with TST and RL 

---
## `main.py`: Application Entry Point and Orchestrator

`main.py`ëŠ” ì „ì²´ ì£¼ì‹ íŠ¸ë ˆì´ë”© ë´‡ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì§„ì…ì ì´ì í•µì‹¬ ë¡œì§ì„ í†µí•©ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì‚¬ìš©ì ì…ë ¥ë¶€í„° ìµœì¢… íŠ¸ë ˆì´ë”© ì¡°ì–¸ ì¶œë ¥ê¹Œì§€ì˜ ì „ ê³¼ì •ì„ ìë™í™”ëœ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥ ë° ì²˜ë¦¬ íë¦„

`main.py`ì˜ `run_trading_bot()` í•¨ìˆ˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¡œ ì‘ë™í•©ë‹ˆë‹¤:

1.  **ì‚¬ìš©ì ì…ë ¥ ìˆ˜ì§‘ (`get_user_input`)**
    *   **ëª©ì **: íŠ¸ë ˆì´ë”© ê²°ì •ì— í•„ìš”í•œ ì´ˆê¸° ì •ë³´ë¥¼ ì‚¬ìš©ìë¡œë¶€í„° ë°›ìŠµë‹ˆë‹¤.
    *   **ì…ë ¥**: (ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì‹œ CLI ë˜ëŠ” GUIë¥¼ í†µí•´)
        *   ê±°ë˜ ëŒ€ìƒ ì¢…ëª© (`ticker`)
        *   í˜„ì¬ ì£¼ì‹ ë³´ìœ  ìƒíƒœ (ë³´ìœ  ì—¬ë¶€, ë³´ìœ ëŸ‰, í‰ë‹¨ê°€)
        *   ì‚¬ìš© ê°€ëŠ¥í•œ íˆ¬ìê¸ˆ (`bullet`)
        *   ì‚¬ìš©ìì˜ ê±°ë˜ ì˜ë„ (ì„ í˜¸ ì•¡ì…˜: ë§¤ìˆ˜/ë§¤ë„, ì˜ì‚¬ ê°•ë„)
        *   ì„ í˜¸í•˜ëŠ” RL ì—ì´ì „íŠ¸ (`PPO` ë˜ëŠ” `SAC`)
    *   **ì¶œë ¥**: ì‚¬ìš©ìì˜ ì…ë ¥ ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬.

2.  **í•µì‹¬ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™” (`initialize_state_variables`)**
    *   **ëª©ì **: ìˆ˜ì§‘ëœ ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„ ë° ê±°ë˜ ë¡œì§ì— ì‚¬ìš©ë  ë‚´ë¶€ ìƒíƒœ ë³€ìˆ˜ë¡œ ê°€ê³µí•©ë‹ˆë‹¤.
    *   **ì…ë ¥**: `get_user_input`ìœ¼ë¡œë¶€í„° ë°›ì€ ì‚¬ìš©ì ì •ë³´ ë”•ì…”ë„ˆë¦¬.
    *   **ì¶œë ¥**: êµ¬ì¡°í™”ëœ í˜„ì¬ ìƒíƒœ ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ (ì˜ˆ: `current_state`).

3.  **ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ë° ê°ì„± ë¶„ì„ (`collect_and_process_news_sentiment`)**
    *   **ëª©ì **: ì„ íƒëœ ì¢…ëª©ì— ëŒ€í•œ ìµœê·¼ ë‰´ìŠ¤(ê¸°ë³¸ 7ì¼)ë¥¼ ìˆ˜ì§‘í•˜ê³ , ê°ì„± ë¶„ì„ì„ í†µí•´ ì‹œì¥ì˜ ì‹¬ë¦¬ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
    *   **ê°€ì • ì˜ì¡´ì„±**: 
        *   `data_collection.news_fetcher`: íŠ¹ì • ì¢…ëª©ì˜ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” ëª¨ë“ˆ.
        *   `analysis.sentiment_analyzer`: ë‰´ìŠ¤ í…ìŠ¤íŠ¸ì˜ ê°ì„±ì„ ë¶„ì„í•˜ëŠ” ëª¨ë“ˆ.
        *   `analysis.news_processor`: ë¶„ì„ëœ ê°ì„± ì ìˆ˜ë¥¼ ì¼ë³„ë¡œ ì§‘ê³„í•˜ëŠ” ëª¨ë“ˆ.
    *   **ì…ë ¥**: ì¢…ëª© ì½”ë“œ (`ticker`), ë¶„ì„ ê¸°ê°„ (ì¼ìˆ˜).
    *   **ì¶œë ¥**: ì¼ë³„ í‰ê·  ê°ì„± ì ìˆ˜ë¥¼ ë‹´ì€ Pandas Series (ë‚ ì§œ ì¸ë±ìŠ¤).

4.  **ê¸°ìˆ ì  ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘ (`collect_technical_analysis_data`)**
    *   **ëª©ì **: ì£¼ê°€ ì˜ˆì¸¡ ë° RL ì—ì´ì „íŠ¸ì˜ ìƒíƒœ êµ¬ì„±ì— í•„ìš”í•œ OHLCV ë° ê°ì¢… ê¸°ìˆ ì  ì§€í‘œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤ (ê¸°ë³¸ 7ì¼).
    *   **ê°€ì • ì˜ì¡´ì„±**: 
        *   `data_collection.ta_fetcher`: OHLCV ë° ê¸°ìˆ ì  ì§€í‘œë¥¼ ê³„ì‚°í•˜ì—¬ ì œê³µí•˜ëŠ” ëª¨ë“ˆ.
    *   **ì…ë ¥**: ì¢…ëª© ì½”ë“œ (`ticker`), ë¶„ì„ ê¸°ê°„ (ì¼ìˆ˜).
    *   **ì¶œë ¥**: OHLCV ë° ê¸°ìˆ ì  ì§€í‘œë¥¼ í¬í•¨í•˜ëŠ” Pandas DataFrame (ë‚ ì§œ ì¸ë±ìŠ¤).

5.  **TST ëª¨ë¸ ê¸°ë°˜ ê°€ê²© ì˜ˆì¸¡ (`predict_price_with_tst_model`)**
    *   **ëª©ì **: ìˆ˜ì§‘ëœ ê¸°ìˆ ì  ë°ì´í„°ì™€ ë‰´ìŠ¤ ê°ì„± ì ìˆ˜ë¥¼ í†µí•©í•˜ì—¬ Time Series Transformer(TST) ëª¨ë¸ì„ í†µí•´ í–¥í›„ ì£¼ê°€ ì›€ì§ì„ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    *   **ê°€ì • ì˜ì¡´ì„±**: 
        *   `models.tst_predictor`: í•™ìŠµëœ TST ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë“ˆ.
    *   **ì…ë ¥**: ê¸°ìˆ ì  ë¶„ì„ ë°ì´í„° (DataFrame), ì¼ë³„ ê°ì„± ì ìˆ˜ (Series).
    *   **ì¶œë ¥**: ê°€ê²© ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (ì˜ˆ: ì˜ˆìƒ ë°©í–¥, ì‹ ë¢°ë„, ì˜ˆìƒ ë³€ë™í­ ë“±).

6.  **RL ì—ì´ì „íŠ¸ ìƒíƒœ ë²¡í„° êµ¬ì„± (`construct_rl_state_vector`)**
    *   **ëª©ì **: ê°•í™”í•™ìŠµ(RL) ì—ì´ì „íŠ¸ê°€ ìµœì ì˜ í–‰ë™ì„ ê²°ì •í•˜ëŠ” ë° í•„ìš”í•œ ëª¨ë“  ì •ë³´ë¥¼ ì§‘ì•½í•˜ì—¬ ìƒíƒœ(state) ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    *   **ì…ë ¥**: ì´ˆê¸° ìƒíƒœ ë³€ìˆ˜, ê¸°ìˆ ì  ë°ì´í„°, ì¼ë³„ ê°ì„± ì ìˆ˜, TST ê°€ê²© ì˜ˆì¸¡ ê²°ê³¼.
    *   **ì¶œë ¥**: RL ì—ì´ì „íŠ¸ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë  ìƒíƒœ ë²¡í„° (ë”•ì…”ë„ˆë¦¬ í˜•íƒœ).

7.  **RL ì—ì´ì „íŠ¸ë¥¼ í†µí•œ ì•¡ì…˜ ê²°ì • (`get_action_from_rl_agent`)**
    *   **ëª©ì **: êµ¬ì„±ëœ ìƒíƒœ ë²¡í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì„ íƒí•œ RL ì—ì´ì „íŠ¸(PPO ë˜ëŠ” SAC)ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ ê±°ë˜ ì•¡ì…˜(ë§¤ìˆ˜, ë§¤ë„, ê´€ë§)ì„ ë„ì¶œí•©ë‹ˆë‹¤.
    *   **ê°€ì • ì˜ì¡´ì„±**: 
        *   `agents.ppo_agent`: PPO ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ RL ì—ì´ì „íŠ¸.
        *   `agents.sac_agent`: SAC ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ RL ì—ì´ì „íŠ¸.
    *   **ì…ë ¥**: ìƒíƒœ ë²¡í„°, ì‚¬ìš©ìê°€ ì„ íƒí•œ ì—ì´ì „íŠ¸ ì´ë¦„.
    *   **ì¶œë ¥**: RL ì—ì´ì „íŠ¸ê°€ ì œì•ˆí•˜ëŠ” ì•¡ì…˜ ë° ê´€ë ¨ ì •ë³´ (ì˜ˆ: ì´ìœ , ëª©í‘œ ê°€ê²© ë“±)ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬.

8.  **ìµœì¢… íŠ¸ë ˆì´ë”© ì¡°ì–¸ ìƒì„± (`generate_final_recommendation`)**
    *   **ëª©ì **: TST ëª¨ë¸ì˜ ì‹œì¥ ì˜ˆì¸¡ê³¼ RL ì—ì´ì „íŠ¸ì˜ í–‰ë™ ê²°ì •ì„ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì´í•´í•˜ê¸° ì‰¬ìš´ ìµœì¢… íŠ¸ë ˆì´ë”© ì¡°ì–¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    *   **ì…ë ¥**: TST ê°€ê²© ì˜ˆì¸¡ ê²°ê³¼, RL ì—ì´ì „íŠ¸ì˜ ê²°ì •.
    *   **ì¶œë ¥**: ì‚¬ìš©ìì—ê²Œ ì œì‹œë  ìµœì¢… ì¶”ì²œ ë©”ì‹œì§€ (ë¬¸ìì—´).

### ì‹¤í–‰ ë°©ë²•

í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ í†µí•´ `main.py`ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
python main.py
```

ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì‹œ, ì½˜ì†”ì„ í†µí•´ í•„ìš”í•œ ì •ë³´(ëª¨ì˜ ì…ë ¥ ë°©ì‹ ì‚¬ìš© ì‹œì—ëŠ” í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©)ë¥¼ ì…ë ¥ë°›ì•„ ì „ì²´ ë¶„ì„ ë° ì¡°ì–¸ ìƒì„± ê³¼ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

### ëª¨ë“ˆ ì˜ì¡´ì„± (ê°€ì •)

`main.py`ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ëª¨ë“ˆ(ë””ë ‰í† ë¦¬)ì— ì˜ì¡´í•˜ëŠ” ê²ƒìœ¼ë¡œ ê°€ì •í•˜ê³  ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì œ êµ¬í˜„ ì‹œ ê° ëª¨ë“ˆ ë‚´ì˜ í•´ë‹¹ ê¸°ëŠ¥ë“¤ì´ ê°œë°œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

*   `config/`: ì „ì—­ ì„¤ì • (ì˜ˆ: API í‚¤, ì§€ì› í‹°ì»¤ ë¦¬ìŠ¤íŠ¸)
*   `data_collection/`: ë°ì´í„° ìˆ˜ì§‘ ê´€ë ¨ ëª¨ë“ˆ (`news_fetcher.py`, `ta_fetcher.py`)
*   `analysis/`: ë°ì´í„° ë¶„ì„ ê´€ë ¨ ëª¨ë“ˆ (`sentiment_analyzer.py`, `news_processor.py`)
*   `models/`: ì˜ˆì¸¡ ëª¨ë¸ ê´€ë ¨ ëª¨ë“ˆ (`tst_predictor.py`)
*   `agents/`: ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ ê´€ë ¨ ëª¨ë“ˆ (`ppo_agent.py`, `sac_agent.py`)

---
## Data Collection Scripts

### Using main.py

í”„ë¡œê·¸ë¨ì˜ ì§„ì…ì ì¸ `main.py`ë¥¼ í†µí•´ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### í”„ë¡œê·¸ë˜ë§¤í‹± ì‚¬ìš©
```python
from main import fetch_recent_data, fetch_all_tickers

# ë‹¨ì¼ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘
success = fetch_recent_data("AAPL", days=30)

# ëª¨ë“  ì§€ì› ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘
results = fetch_all_tickers(days=30)
```

#### ì»¤ë§¨ë“œ ë¼ì¸ ì‹¤í–‰
```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰
python main.py
```

### ta_fetcher.py

`ta_fetcher.py`ëŠ” ë‹¨ì¼ ì£¼ì‹ ì¢…ëª©ì˜ ìµœê·¼ 30ì¼ê°„ì˜ OHLCV(Open, High, Low, Close, Volume) ë°ì´í„°ì™€ ê¸°ìˆ ì  ì§€í‘œ(Technical Indicators)ë¥¼ ìˆ˜ì§‘í•˜ê³  ê³„ì‚°í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

#### ì…ë ¥ (Inputs)
- **ì¢…ëª© ì½”ë“œ (Ticker Symbol)**
  - `config/tickers.py`ì— ì •ì˜ëœ `SUPPORTED_TICKERS` ë¦¬ìŠ¤íŠ¸ ë‚´ì˜ ì¢…ëª©ë§Œ ì²˜ë¦¬ ê°€ëŠ¥
  - ìŠ¤í¬ë¦½íŠ¸ ë‚´ì˜ `target_ticker` ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì—¬ ì›í•˜ëŠ” ì¢…ëª© ì„ íƒ (ê¸°ë³¸ê°’: "AAPL")
- **ë‚ ì§œ ë²”ìœ„**
  - ìë™ìœ¼ë¡œ ê³„ì‚°ë¨:
    - ì¢…ë£Œì¼(end_date): ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œì 
    - ì‹œì‘ì¼(start_date): ì¢…ë£Œì¼ë¡œë¶€í„° 30ì¼ ì „

#### ì²˜ë¦¬ ê³¼ì • (Process)
1. **ë°ì´í„° ìˆ˜ì§‘**
   - yfinance APIë¥¼ í†µí•´ ì§€ì •ëœ ì¢…ëª©ì˜ OHLCV ë°ì´í„° ìˆ˜ì§‘
   - ì„¤ì •ëœ ë‚ ì§œ ë²”ìœ„(30ì¼) ë™ì•ˆì˜ ì¼ë³„ ë°ì´í„° íšë“

2. **ë°ì´í„° ì „ì²˜ë¦¬**
   - 'Date' ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
   - DatetimeIndexë¡œ ì„¤ì •í•˜ì—¬ ì‹œê³„ì—´ ë°ì´í„° êµ¬ì¡° ìƒì„±

3. **ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°**
   - `feature_engineering/ta_calculator.py`ì˜ `calculate_technical_indicators` í•¨ìˆ˜ ì‚¬ìš©
   - OHLCV ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì–‘í•œ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
   - ì›ë³¸ OHLCV ë°ì´í„°ë„ í¬í•¨ (include_ohlcv=True)

#### ì¶œë ¥ (Outputs)
- **CSV íŒŒì¼**
  - íŒŒì¼ëª…: `{ì¢…ëª©ì½”ë“œ}_last_30days_features.csv` (ì˜ˆ: `AAPL_last_30days_features.csv`)
  - í¬í•¨ ë°ì´í„°:
    - ì¸ë±ìŠ¤: Date (ë‚ ì§œ)
    - ì»¬ëŸ¼: 
      - OHLCV (Open, High, Low, Close, Volume)
      - ê³„ì‚°ëœ ëª¨ë“  ê¸°ìˆ ì  ì§€í‘œë“¤

#### ì‹¤í–‰ ë°©ë²•
```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰
python data_collection/ta_fetcher.py
```

#### ì£¼ì˜ì‚¬í•­
- ìŠ¤í¬ë¦½íŠ¸ëŠ” ë°˜ë“œì‹œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤
- ìŠ¤í¬ë¦½íŠ¸ëŠ” `config/tickers.py`ì— ì •ì˜ëœ ì¢…ëª©ë§Œ ì²˜ë¦¬ ê°€ëŠ¥
- ë‹¤ë¥¸ ì¢…ëª©ì„ ì²˜ë¦¬í•˜ë ¤ë©´ ìŠ¤í¬ë¦½íŠ¸ ë‚´ì˜ `target_ticker` ê°’ì„ ìˆ˜ì •í•´ì•¼ í•¨
- `feature_engineering/ta_calculator.py` ëª¨ë“ˆì´ í•„ìš”í•˜ë©° Python ê²½ë¡œì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•´ì•¼ í•¨
- ì‹¤í–‰ ì‹œì ìœ¼ë¡œë¶€í„° 30ì¼ ì „ì˜ ë°ì´í„°ë§Œ ì²˜ë¦¬ë¨

---

## News Processor (`news_processor.py`)

### ê°œìš”

`feature_engineering/news_processor.py`ëŠ” ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ê²°ê³¼ë¥¼ ì¼ë³„ íŠ¹ì„±ìœ¼ë¡œ ì§‘ê³„í•˜ëŠ” í•µì‹¬ ëª¨ë“ˆì…ë‹ˆë‹¤. ê°œë³„ í—¤ë“œë¼ì¸ì˜ ê°ì„± ì ìˆ˜ë¥¼ ì¼ë³„ë¡œ í†µí•©í•˜ê³ , ì£¼ë§ ë‰´ìŠ¤ì˜ ì˜í–¥ì„ ë‹¤ìŒ ì£¼ ì˜ì—…ì¼ì— ì „íŒŒí•˜ëŠ” ê³ ê¸‰ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥

#### 1. **ì¼ë³„ ê°ì„± ì§‘ê³„**
- ê°œë³„ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì˜ ê°ì„± ì ìˆ˜ë¥¼ ì¼ë³„ë¡œ í‰ê· í™”
- í•˜ë£¨ ë‚´ ì—¬ëŸ¬ ë‰´ìŠ¤ê°€ ìˆì„ ê²½ìš° ê°ì„± ì ìˆ˜ í†µê³„ ì²˜ë¦¬
- ë‰´ìŠ¤ ê°œìˆ˜ ì¹´ìš´íŒ…ìœ¼ë¡œ ì‹œì¥ ê´€ì‹¬ë„ ì¸¡ì •

#### 2. **ì£¼ë§ íš¨ê³¼ ëª¨ë¸ë§**
- ì£¼ë§ ë°œí–‰ ë‰´ìŠ¤ì˜ ê°ì„±ì´ ë‹¤ìŒ ì£¼ ì˜ì—…ì¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ì •ëŸ‰í™”
- í† ìš”ì¼/ì¼ìš”ì¼ ë‰´ìŠ¤ â†’ ë‹¤ìŒ ì£¼ ì›”~ê¸ˆìš”ì¼ 5ì˜ì—…ì¼ì— íš¨ê³¼ ì „íŒŒ
- ë³µìˆ˜ ì£¼ë§ ë‰´ìŠ¤ ì‹œ í‰ê·  íš¨ê³¼ ê³„ì‚°

#### 3. **ì˜ì—…ì¼ ê¸°ë°˜ ì²˜ë¦¬**
- ë¯¸êµ­ ì¦ì‹œ ì˜ì—…ì¼ (ì›”~ê¸ˆ) ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ì •ë ¬
- ì£¼ë§/ê³µíœ´ì¼ ì œì™¸ ì²˜ë¦¬
- ì˜ì—…ì¼ ì‹œí€€ìŠ¤ ìë™ ìƒì„±

### í•µì‹¬ í•¨ìˆ˜ ë¶„ì„

#### `is_us_business_day(dt_date: date) -> bool`
```python
def is_us_business_day(dt_date: date):
    # Monday(0) to Friday(4)
    return dt_date.weekday() < 5
```
- **ëª©ì **: í•´ë‹¹ ë‚ ì§œê°€ ë¯¸êµ­ ì˜ì—…ì¼ì¸ì§€ íŒë‹¨
- **ê¸°ì¤€**: ì›”ìš”ì¼(0) ~ ê¸ˆìš”ì¼(4)
- **ì œí•œ**: ì—°ë°© ê³µíœ´ì¼ì€ ê³ ë ¤í•˜ì§€ ì•ŠìŒ (ë‹¨ìˆœí™”)

#### `get_next_n_business_days(start_date: date, n: int) -> List[date]`
```python
def get_next_n_business_days(start_date: date, n: int):
    business_days = []
    current_date = start_date
    while len(business_days) < n:
        if is_us_business_day(current_date):
            business_days.append(current_date)
        current_date += timedelta(days=1)
    return business_days
```
- **ëª©ì **: ì‹œì‘ì¼ë¶€í„° Nê°œì˜ ì˜ì—…ì¼ ìƒì„±
- **ì‚¬ìš©**: ì£¼ë§ ë‰´ìŠ¤ íš¨ê³¼ë¥¼ ì „íŒŒí•  ì˜ì—…ì¼ ê³„ì‚°

#### `aggregate_daily_sentiment_features(analyzed_news_df: pd.DataFrame, ticker_symbol: str) -> pd.DataFrame`

ì£¼ìš” ì§‘ê³„ í•¨ìˆ˜ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤:

### ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

#### 1. **ì…ë ¥ ë°ì´í„° ê²€ì¦**
```python
required_cols = ['published_date', 'sentiment_positive', 'sentiment_negative', 'sentiment_neutral']
```
- **í•„ìˆ˜ ì»¬ëŸ¼**: ë°œí–‰ì¼, 3ê°€ì§€ ê°ì„± ì ìˆ˜
- **ë‚ ì§œ í˜•ì‹ í†µì¼**: Timestamp â†’ date ê°ì²´ë¡œ ë³€í™˜

#### 2. **ì¼ë³„ ê¸°ë³¸ ì§‘ê³„**
```python
daily_aggregated_sentiments = df.groupby('published_date').agg(
    avg_sentiment_positive=('sentiment_positive', 'mean'),
    avg_sentiment_negative=('sentiment_negative', 'mean'),
    avg_sentiment_neutral=('sentiment_neutral', 'mean'),
    news_count=('headline', 'count')
)
```

#### 3. **ì£¼ë§ íš¨ê³¼ ì „íŒŒ**
```python
# ì£¼ë§ ë‰´ìŠ¤ ì‹ë³„
if not is_us_business_day(current_date): # í† ìš”ì¼ ë˜ëŠ” ì¼ìš”ì¼
    # ë‹¤ìŒ ì›”ìš”ì¼ë¶€í„° 5ì˜ì—…ì¼ì— íš¨ê³¼ ì „íŒŒ
    start_propagation_date = current_date + timedelta(days=(7 - current_date.weekday()))
    target_business_days = get_next_n_business_days(start_propagation_date, 5)
```

#### 4. **ë°ì´í„° ë³‘í•© ë° ìµœì¢… ì²˜ë¦¬**
```python
# í‰ì¼ ì§‘ê³„ + ì£¼ë§ íš¨ê³¼ë¥¼ í•©ì„±
final_df = pd.merge(all_dates.to_frame(), daily_aggregated_sentiments, on='date', how='left')
final_df = pd.merge(final_df, weekend_effects_df, on='date', how='left')
```

### ì¶œë ¥ íŠ¹ì„±

#### ìƒì„±ë˜ëŠ” ì»¬ëŸ¼ë“¤

| ì»¬ëŸ¼ëª… | ì„¤ëª… | ë²”ìœ„ |
|--------|------|------|
| `avg_sentiment_positive` | ì¼ë³„ í‰ê·  ê¸ì • ê°ì„± | 0.0 ~ 1.0 |
| `avg_sentiment_negative` | ì¼ë³„ í‰ê·  ë¶€ì • ê°ì„± | 0.0 ~ 1.0 |
| `avg_sentiment_neutral` | ì¼ë³„ í‰ê·  ì¤‘ë¦½ ê°ì„± | 0.0 ~ 1.0 |
| `news_count` | ì¼ë³„ ë‰´ìŠ¤ ê°œìˆ˜ | ì •ìˆ˜ |
| `weekend_effect_positive` | ì£¼ë§ ë‰´ìŠ¤ ê¸ì • íš¨ê³¼ | 0.0 ~ 1.0 |
| `weekend_effect_negative` | ì£¼ë§ ë‰´ìŠ¤ ë¶€ì • íš¨ê³¼ | 0.0 ~ 1.0 |
| `weekend_effect_neutral` | ì£¼ë§ ë‰´ìŠ¤ ì¤‘ë¦½ íš¨ê³¼ | 0.0 ~ 1.0 |

#### ë°ì´í„° êµ¬ì¡°
- **ì¸ë±ìŠ¤**: `date` (ë‚ ì§œë³„ ì •ë ¬)
- **ëŒ€ìƒ**: ì˜ì—…ì¼ ì¤‘ì‹¬ (ì£¼ë§ì€ íš¨ê³¼ë¡œë§Œ ë°˜ì˜)
- **ê²°ì¸¡ê°’ ì²˜ë¦¬**: ë‰´ìŠ¤ê°€ ì—†ëŠ” ë‚ ì€ 0.0ìœ¼ë¡œ ì±„ì›€

### ì£¼ë§ íš¨ê³¼ ë¡œì§ ìƒì„¸

#### ì „íŒŒ ë©”ì»¤ë‹ˆì¦˜
```
í† ìš”ì¼ ë‰´ìŠ¤ â†’ ë‹¤ìŒ ì£¼ ì›”~ê¸ˆ (5ì˜ì—…ì¼)
ì¼ìš”ì¼ ë‰´ìŠ¤ â†’ ë‹¤ìŒ ì£¼ ì›”~ê¸ˆ (5ì˜ì—…ì¼)
```

#### ì˜ˆì‹œ: 2023ë…„ 10ì›” 21ì¼(í† ) ë‰´ìŠ¤
- **ë°œí–‰ì¼**: 2023-10-21 (í† ìš”ì¼)
- **ì˜í–¥ ëŒ€ìƒ**: 2023-10-23(ì›”) ~ 2023-10-27(ê¸ˆ)
- **íš¨ê³¼**: í† ìš”ì¼ ë‰´ìŠ¤ì˜ ê°ì„± ì ìˆ˜ê°€ 5ì˜ì—…ì¼ì— ë™ì¼í•˜ê²Œ ì ìš©

#### ë³µìˆ˜ ì£¼ë§ ë‰´ìŠ¤ ì²˜ë¦¬
```python
# ê°™ì€ ì˜ì—…ì¼ì— ì—¬ëŸ¬ ì£¼ë§ ë‰´ìŠ¤ íš¨ê³¼ê°€ ê²¹ì¹˜ë©´ í‰ê·  ê³„ì‚°
weekend_effects_df = weekend_effects_df.groupby('date').agg({
    'weekend_effect_positive': 'mean',
    'weekend_effect_negative': 'mean',
    'weekend_effect_neutral': 'mean'
})
```

### ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ

#### ì…ë ¥ ë°ì´í„° (ë¶„ì„ëœ ë‰´ìŠ¤)
```python
analyzed_news_df = pd.DataFrame([
    {'published_date': date(2023,10,20), 'sentiment_positive': 0.3, 'sentiment_negative': 0.1, 'sentiment_neutral': 0.6},  # ê¸ˆìš”ì¼
    {'published_date': date(2023,10,21), 'sentiment_positive': 0.8, 'sentiment_negative': 0.1, 'sentiment_neutral': 0.1},  # í† ìš”ì¼ (ì£¼ë§)
    {'published_date': date(2023,10,23), 'sentiment_positive': 0.2, 'sentiment_negative': 0.3, 'sentiment_neutral': 0.5},  # ì›”ìš”ì¼
])
```

#### ì¶œë ¥ ê²°ê³¼
```python
# 2023-10-20 (ê¸ˆìš”ì¼)
avg_sentiment_positive: 0.3, weekend_effect_positive: 0.0

# 2023-10-23 (ì›”ìš”ì¼) 
avg_sentiment_positive: 0.2, weekend_effect_positive: 0.8  # í† ìš”ì¼ ë‰´ìŠ¤ íš¨ê³¼
```

### íŠ¹ì§• ë° ì¥ì 

#### 1. **í˜„ì‹¤ì ì¸ ì‹œì¥ ëª¨ë¸ë§**
- ì£¼ë§ ë‰´ìŠ¤ê°€ ì›”ìš”ì¼ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì •ëŸ‰í™”
- ì˜ì—…ì¼ ê¸°ì¤€ ë°ì´í„° ì •ë ¬ë¡œ ì‹¤ì œ ê±°ë˜ì¼ì •ê³¼ ì¼ì¹˜

#### 2. **Robustí•œ ë°ì´í„° ì²˜ë¦¬**
- ê²°ì¸¡ê°’ ìë™ ì²˜ë¦¬ (ë‰´ìŠ¤ ì—†ëŠ” ë‚  = 0)
- ë‚ ì§œ í˜•ì‹ ìë™ ë³€í™˜
- ì—ëŸ¬ ìƒí™© ëŒ€ì‘ (ë¹ˆ ë°ì´í„°, ì»¬ëŸ¼ ëˆ„ë½)

#### 3. **ìœ ì—°í•œ ì§‘ê³„ ë°©ì‹**
- í•˜ë£¨ ë‚´ ë³µìˆ˜ ë‰´ìŠ¤ì˜ í‰ê·  ê°ì„± ê³„ì‚°
- ì£¼ë§ íš¨ê³¼ì˜ í‰ê· í™” ì²˜ë¦¬
- í™•ì¥ ê°€ëŠ¥í•œ ê°ì„± íŠ¹ì„± êµ¬ì¡°

#### 4. **í†µê³„ì  ê·¼ê±°**
- ê°ì„± ì ìˆ˜ì˜ í™•ë¥ ì  ë¶„í¬ (positive + negative + neutral = 1.0)
- ë‰´ìŠ¤ ë¹ˆë„ë¥¼ í†µí•œ ì‹œì¥ ê´€ì‹¬ë„ ì¸¡ì •
- ì‹œê°„ ì§€ì—° íš¨ê³¼ ëª¨ë¸ë§

### í†µí•© ì—­í• 

ì´ ëª¨ë“ˆì€ ì£¼ì‹ íŠ¸ë ˆì´ë”© ë´‡ ì‹œìŠ¤í…œì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:

1. **ê°ì„± ì‹ í˜¸ ìƒì„±**: ì›ì‹œ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ â†’ ì •ëŸ‰ì  ê°ì„± ì§€í‘œ
2. **ì‹œê°„ ì •ë ¬**: ë‰´ìŠ¤ ì‹œì ê³¼ ê±°ë˜ ì‹œì  ê°„ì˜ ì‹œê°„ ì •í•©ì„± í™•ë³´  
3. **íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§**: ML ëª¨ë¸ì´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë°ì´í„° ë³€í™˜
4. **ì‹œì¥ ì‹¬ë¦¬ ë°˜ì˜**: íˆ¬ììë“¤ì˜ ê°ì •ì  ë°˜ì‘ì„ ìˆ˜ì¹˜í™”

ì´ë¥¼ í†µí•´ TST ëª¨ë¸ê³¼ RL ì—ì´ì „íŠ¸ê°€ **ë‰´ìŠ¤ ê¸°ë°˜ ì‹œì¥ ì„¼í‹°ë©˜íŠ¸**ë¥¼ ì˜ì‚¬ê²°ì •ì— í™œìš©í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.

---

## TST Model VRAM ì‚¬ìš©ëŸ‰ ë¶„ì„

### ëª¨ë¸ íŒŒë¼ë¯¸í„° ê¸°ë°˜ ë©”ëª¨ë¦¬ ê³„ì‚°

#### í˜„ì¬ ëª¨ë¸ ì„¤ì •
```python
DEFAULT_MODEL_CONFIG = {
    'input_size': 88,           # 81 TA + 7 News features
    'prediction_length': 10,    # 10ì¼ ì˜ˆì¸¡
    'context_length': 60,       # 60ì¼ íˆìŠ¤í† ë¦¬
    'n_layer': 3,              # 3 encoder + 3 decoder layers
    'n_head': 4,               # 4 attention heads
    'd_model': 128,            # 128 ì°¨ì› íŠ¸ëœìŠ¤í¬ë¨¸
    'rl_state_size': 256,      # 256 ì°¨ì› RL ìƒíƒœ ë²¡í„°
    'batch_size': 32           # ë°°ì¹˜ í¬ê¸° (í›ˆë ¨ ì‹œ)
}
```

### íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°

#### 1. **TimeSeriesTransformer êµ¬ì„±ìš”ì†Œ**

**Embedding Layers**:
```
- Input Embedding: 88 Ã— 128 = 11,264 params
- Position Embedding: 60 Ã— 128 = 7,680 params
- Total Embedding: ~19K params
```

**Encoder Layers (3ê°œ)**:
```
ê° ë ˆì´ì–´ë‹¹:
- Multi-Head Attention: 4 Ã— (128 Ã— 128 Ã— 3) + bias = ~197K params
- Layer Norm: 128 Ã— 2 = 256 params  
- Feed Forward: 128 Ã— 512 + 512 Ã— 128 + bias = ~131K params
- Layer Norm: 128 params

ë ˆì´ì–´ë‹¹ ì´í•©: ~328K params
3ê°œ ë ˆì´ì–´: ~984K params
```

**Decoder Layers (3ê°œ)**:
```
ê° ë ˆì´ì–´ë‹¹:
- Self-Attention: ~197K params
- Cross-Attention: ~197K params  
- Feed Forward: ~131K params
- Layer Norms: ~400 params

ë ˆì´ì–´ë‹¹ ì´í•©: ~525K params
3ê°œ ë ˆì´ì–´: ~1.6M params
```

**Output Projection**:
```
- Final Linear: 128 Ã— 88 = 11,264 params
- Distribution params (mean, std): ì¶”ê°€ íŒŒë¼ë¯¸í„°
```

#### 2. **RL Head**
```
- Linear Layer: (10 Ã— 88) Ã— 256 + 256 bias = 225,536 params
```

#### 3. **ì´ íŒŒë¼ë¯¸í„° ìˆ˜ ì¶”ì •**
```
- TimeSeriesTransformer: ~2.8M params
- RL Head: ~225K params
- Total: ~3.0M params
```

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°

#### **ì¶”ë¡  ì‹œ (Inference)**

**ëª¨ë¸ íŒŒë¼ë¯¸í„°**:
```
3,000,000 params Ã— 4 bytes (float32) = 12 MB
```

**ì…ë ¥ ë°ì´í„°** (ë‹¨ì¼ ì¢…ëª©):
```
Batch Ã— Context Ã— Features Ã— 4 bytes
= 1 Ã— 60 Ã— 88 Ã— 4 = 21,120 bytes â‰ˆ 21 KB
```

**ì¤‘ê°„ í™œì„±í™” ë©”ëª¨ë¦¬**:
```
- Attention í–‰ë ¬: 4 heads Ã— 60 Ã— 60 Ã— 4 bytes = 57.6 KB
- Hidden states: 60 Ã— 128 Ã— 4 bytes = 30.7 KB  
- Feed forward: 60 Ã— 512 Ã— 4 bytes = 122.8 KB
- ê¸°íƒ€ ì¤‘ê°„ ê³„ì‚°: ~200 KB

ì´ ì¤‘ê°„ í™œì„±í™”: ~411 KB
```

**RL State ì¶œë ¥**:
```
1 Ã— 256 Ã— 4 bytes = 1,024 bytes â‰ˆ 1 KB
```

**ì¶”ë¡  ì‹œ ì´ VRAM**: **ì•½ 13-15 MB**

#### **í›ˆë ¨ ì‹œ (Training)**

**ëª¨ë¸ íŒŒë¼ë¯¸í„°**: 12 MB (ë™ì¼)

**ë°°ì¹˜ ì…ë ¥ ë°ì´í„°**:
```
ë°°ì¹˜ Ã— (ê³¼ê±° + ë¯¸ë˜) Ã— íŠ¹ì„± Ã— 4 bytes
= 32 Ã— (60 + 10) Ã— 88 Ã— 4 = 787,456 bytes â‰ˆ 787 KB
```

**ê·¸ë˜ë””ì–¸íŠ¸ ë©”ëª¨ë¦¬**:
```
íŒŒë¼ë¯¸í„°ì™€ ë™ì¼í•œ í¬ê¸°: 12 MB
```

**ì˜µí‹°ë§ˆì´ì € ìƒíƒœ (AdamW)**:
```
- Momentum: 12 MB
- Variance: 12 MB  
- Total: 24 MB
```

**ì¤‘ê°„ í™œì„±í™” (ë°°ì¹˜ë³„)**:
```
- Attention: 32 Ã— 4 Ã— 60 Ã— 60 Ã— 4 = 1.8 MB
- Hidden states: 32 Ã— 60 Ã— 128 Ã— 4 = 983 KB
- Feed forward: 32 Ã— 60 Ã— 512 Ã— 4 = 3.9 MB
- ë°±ì›Œë“œ íŒ¨ìŠ¤ìš© ì¶”ê°€ ë©”ëª¨ë¦¬: ~5 MB

ì´ í™œì„±í™”: ~12 MB
```

**í›ˆë ¨ ì‹œ ì´ VRAM**: **ì•½ 60-70 MB**

### ì‹¤ì œ VRAM ì‚¬ìš©ëŸ‰ ì¸¡ì • ì½”ë“œ

```python
import torch
import psutil
import GPUtil

def measure_model_memory():
    """TST ëª¨ë¸ì˜ ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •"""
    
    # GPU ë©”ëª¨ë¦¬ ì¸¡ì • (CUDA ì‚¬ìš© ì‹œ)
    if torch.cuda.is_available():
        device = torch.device('cuda')
        torch.cuda.empty_cache()
        
        # ì´ˆê¸° GPU ë©”ëª¨ë¦¬
        initial_memory = torch.cuda.memory_allocated() / 1024**2  # MB
        
        # ëª¨ë¸ ë¡œë“œ
        model = TSTModel(DEFAULT_MODEL_CONFIG).to(device)
        model_memory = torch.cuda.memory_allocated() / 1024**2 - initial_memory
        
        # ì¶”ë¡  í…ŒìŠ¤íŠ¸
        dummy_input = torch.randn(1, 60, 88).to(device)
        model.eval()
        with torch.no_grad():
            _ = model(dummy_input)
        inference_memory = torch.cuda.memory_allocated() / 1024**2 - initial_memory
        
        # í›ˆë ¨ í…ŒìŠ¤íŠ¸
        model.train()
        dummy_target = torch.randn(1, 10, 88).to(device)
        output = model(dummy_input, dummy_target)
        loss = output.loss
        loss.backward()
        training_memory = torch.cuda.memory_allocated() / 1024**2 - initial_memory
        
        return {
            'model_params_mb': model_memory,
            'inference_mb': inference_memory, 
            'training_mb': training_memory,
            'total_params': sum(p.numel() for p in model.parameters())
        }
    
    else:
        # CPU ë©”ëª¨ë¦¬ ì¸¡ì •
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024**2
        
        model = TSTModel(DEFAULT_MODEL_CONFIG)
        model_memory = process.memory_info().rss / 1024**2 - initial_memory
        
        return {
            'model_params_mb': model_memory,
            'cpu_memory': True,
            'total_params': sum(p.numel() for p in model.parameters())
        }

# ì‚¬ìš© ì˜ˆì‹œ
print("=== TST Model Memory Usage ===")
memory_stats = measure_model_memory()
for key, value in memory_stats.items():
    print(f"{key}: {value}")
```

### ë©”ëª¨ë¦¬ ìµœì í™” ë°©ì•ˆ

#### 1. **ì¶”ë¡  ìµœì í™”**
```python
# Mixed Precision ì‚¬ìš©
model = model.half()  # float16 ì‚¬ìš© ì‹œ ë©”ëª¨ë¦¬ 50% ì ˆì•½

# ë°°ì¹˜ í¬ê¸° ì¡°ì •
PREDICT_CONFIG['batch_size'] = 1  # ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œ
```

#### 2. **í›ˆë ¨ ìµœì í™”**
```python
# Gradient Accumulation
effective_batch_size = 32
actual_batch_size = 8  # ë©”ëª¨ë¦¬ì— ë§ê²Œ ì¡°ì •
accumulation_steps = effective_batch_size // actual_batch_size

# Mixed Precision Training
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()

with autocast():
    output = model(past_values, future_values)
    loss = output.loss / accumulation_steps
scaler.scale(loss).backward()
```

#### 3. **ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§**
```python
# ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ì¶”ì 
def log_memory_usage(stage_name):
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**2
        cached = torch.cuda.memory_reserved() / 1024**2
        print(f"{stage_name} - Allocated: {allocated:.1f}MB, Cached: {cached:.1f}MB")
```

### í•˜ë“œì›¨ì–´ ê¶Œì¥ì‚¬í•­

#### **ìµœì†Œ ìš”êµ¬ì‚¬í•­**
- **GPU**: 2GB VRAM (GTX 1060, RTX 3050 ê¸‰)
- **ìš©ë„**: ì¶”ë¡  ì „ìš©, ì‘ì€ ë°°ì¹˜ í¬ê¸°

#### **ê¶Œì¥ ì‚¬ì–‘**
- **GPU**: 4-6GB VRAM (RTX 3060, RTX 4060 ê¸‰)  
- **ìš©ë„**: íš¨ìœ¨ì ì¸ í›ˆë ¨ ë° ì¶”ë¡ 

#### **ìµœì  í™˜ê²½**
- **GPU**: 8GB+ VRAM (RTX 3070, RTX 4070 ê¸‰)
- **ìš©ë„**: ëŒ€ìš©ëŸ‰ ë°°ì¹˜, ë‹¤ì¤‘ ëª¨ë¸ ì‹¤í—˜

### ì‹¤ì œ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ (ì˜ˆìƒ)

| ì‘ì—… ëª¨ë“œ | ë°°ì¹˜ í¬ê¸° | VRAM ì‚¬ìš©ëŸ‰ | ì²˜ë¦¬ ì†ë„ |
|-----------|-----------|-------------|-----------|
| ì¶”ë¡  (ë‹¨ì¼) | 1 | ~15MB | ~50ms |
| ì¶”ë¡  (ë°°ì¹˜) | 32 | ~45MB | ~200ms |
| í›ˆë ¨ (ì†Œí˜•) | 8 | ~35MB | ~500ms |
| í›ˆë ¨ (í‘œì¤€) | 32 | ~70MB | ~1500ms |

ì´ ë¶„ì„ì„ í†µí•´ **ëŒ€ë¶€ë¶„ì˜ í˜„ëŒ€ì ì¸ GPUì—ì„œ ë¬´ë¦¬ ì—†ì´ ì‹¤í–‰ ê°€ëŠ¥**í•˜ë©°, íŠ¹íˆ ì¶”ë¡  ì‘ì—…ì€ ë§¤ìš° ê°€ë²¼ìš´ ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­ì„ ê°€ì§€ê³  ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## TST Model Prediction System (`predict.py`)

### ê°œìš”

`tst_model/predict.py`ëŠ” í›ˆë ¨ëœ Time Series Transformer (TST) ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì£¼ì‹ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ë° ê°•í™”í•™ìŠµ ìƒíƒœ ë²¡í„° ìƒì„±ì„ ìˆ˜í–‰í•˜ëŠ” ì¶”ë¡  ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ ëª¨ë“ˆì€ ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ë´‡ì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œë¡œ, ë‘ ê°€ì§€ ì£¼ìš” ì¶œë ¥ ëª¨ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### í•µì‹¬ ê¸°ëŠ¥

#### 1. **RL State Mode (ê¸°ë³¸ ëª¨ë“œ)**
- **ëª©ì **: ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ê°€ ì˜ì‚¬ê²°ì •ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì••ì¶•ëœ ìƒíƒœ ë²¡í„° ìƒì„±
- **ì¶œë ¥**: 256ì°¨ì›ì˜ ê³ ì°¨ì› íŠ¹ì„± ë²¡í„° (.npy íŒŒì¼)
- **ìš©ë„**: PPO, SAC ë“± RL ì—ì´ì „íŠ¸ì˜ ì…ë ¥ìœ¼ë¡œ í™œìš©

#### 2. **Forecast Mode**
- **ëª©ì **: í–¥í›„ 10ì¼ê°„ì˜ ëª¨ë“  ê¸°ìˆ ì  ì§€í‘œ ì˜ˆì¸¡
- **ì¶œë ¥**: 10Ã—87 ì°¨ì›ì˜ ë¯¸ë˜ ì˜ˆì¸¡ê°’ (.csv íŒŒì¼)
- **ìš©ë„**: ì§ì ‘ì ì¸ ì£¼ê°€ ì˜ˆì¸¡ ë° íŠ¸ë Œë“œ ë¶„ì„

### ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

#### **ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**

```mermaid
graph LR
    A[Raw Historical Data] --> B[Feature Engineering]
    B --> C[Synthetic News Features]
    C --> D[MinMax Scaling]
    D --> E[Sequence Creation]
    E --> F[TST Model]
    F --> G{Mode Selection}
    G -->|RL State| H[256D Vector]
    G -->|Forecast| I[10Ã—87 Predictions]
```

#### **ëª¨ë¸ ì„¤ì • (train.pyì™€ í†µì¼)**

```python
DEFAULT_MODEL_CONFIG = {
    'input_size': 87,           # 80 TA + 7 News features
    'prediction_length': 10,    # 10ì¼ ë¯¸ë˜ ì˜ˆì¸¡
    'context_length': 60,       # 60ì¼ ê³¼ê±° ì»¨í…ìŠ¤íŠ¸
    'n_layer': 4,              # 4ê°œ íŠ¸ëœìŠ¤í¬ë¨¸ ë ˆì´ì–´
    'n_head': 8,               # 8ê°œ ì–´í…ì…˜ í—¤ë“œ
    'd_model': 128,            # 128ì°¨ì› ëª¨ë¸
    'rl_state_size': 256,      # 256ì°¨ì› RL ìƒíƒœ ë²¡í„°
}
```

### ì‚¬ìš©ë²•

#### **ê¸°ë³¸ ì‹¤í–‰ (RL State ëª¨ë“œ)**
```bash
# ëª¨ë“  í‹°ì»¤ì— ëŒ€í•´ RL ìƒíƒœ ë²¡í„° ìƒì„±
python tst_model/predict.py

# íŠ¹ì • í‹°ì»¤ë§Œ ì²˜ë¦¬
python tst_model/predict.py --ticker AAPL

# ì‚¬ìš©ì ì •ì˜ ë°ì´í„° ê²½ë¡œ
python tst_model/predict.py --data_path custom_data.csv
```

#### **Forecast ëª¨ë“œ**
```bash
# íŠ¹ì • í‹°ì»¤ì˜ ë¯¸ë˜ ì˜ˆì¸¡
python tst_model/predict.py --ticker AAPL --mode forecast

# ëª¨ë“  í‹°ì»¤ì˜ ë¯¸ë˜ ì˜ˆì¸¡
python tst_model/predict.py --mode forecast
```

#### **ê³ ê¸‰ ì˜µì…˜**
```bash
python tst_model/predict.py \
    --ticker AAPL \
    --mode rl_state \
    --model_dir ./custom_models \
    --data_path ./custom_data.csv \
    --output_dir ./custom_output
```

### ì¶œë ¥ íŒŒì¼ ë¶„ì„

#### **1. RL State Vectors (.npy íŒŒì¼)**

**íŒŒì¼ êµ¬ì¡°**:
```
AAPL_rl_state_20250524_123646.npy
â”œâ”€â”€ Shape: (256,)           # 256ì°¨ì› ë²¡í„°
â”œâ”€â”€ Type: float32           # 32ë¹„íŠ¸ ë¶€ë™ì†Œìˆ˜ì 
â”œâ”€â”€ Range: [-0.227, 0.210]  # ì •ê·œí™”ëœ ê°’ ë²”ìœ„
â””â”€â”€ Stats: Î¼=0.003, Ïƒ=0.081 # í‰ê· ê³¼ í‘œì¤€í¸ì°¨
```

**ë°ì´í„° ì˜ë¯¸**:
- **ì••ì¶•ëœ ì‹œì¥ ìƒíƒœ**: 60ì¼ê°„ì˜ ê¸°ìˆ ì  ì§€í‘œì™€ ë‰´ìŠ¤ ê°ì„±ì„ 256ì°¨ì›ìœ¼ë¡œ ì••ì¶•
- **ì‹œê°„ì  íŒ¨í„´**: íŠ¸ëœìŠ¤í¬ë¨¸ê°€ í•™ìŠµí•œ ì‹œê³„ì—´ íŒ¨í„´ì˜ ì¶”ìƒì  í‘œí˜„
- **ì˜ì‚¬ê²°ì • ê¸°ë°˜**: RL ì—ì´ì „íŠ¸ê°€ ë§¤ìˆ˜/ë§¤ë„/ê´€ë§ ê²°ì •ì— ì‚¬ìš©

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
import numpy as np

# RL ìƒíƒœ ë²¡í„° ë¡œë“œ
rl_state = np.load('tst_predictions/AAPL_rl_state_20250524_123646.npy')

# RL ì—ì´ì „íŠ¸ì— ì…ë ¥
action = rl_agent.predict(rl_state)  # ì˜ˆ: 0=Hold, 1=Buy, 2=Sell
confidence = rl_agent.get_confidence(rl_state)
```

#### **2. Forecast Predictions (.csv íŒŒì¼)**

**íŒŒì¼ êµ¬ì¡°**:
```
TEST1_forecast_20250524_123639.csv
â”œâ”€â”€ Shape: (10, 88)         # 10ì¼ Ã— 88ê°œ íŠ¹ì„±
â”œâ”€â”€ Index: prediction_day   # 0~9ì¼ (ë¯¸ë˜ ì˜ˆì¸¡ ì¼ìˆ˜)
â”œâ”€â”€ Columns: 0~86          # 87ê°œ ì •ê·œí™”ëœ íŠ¹ì„±ê°’
â””â”€â”€ Values: [0.0, 1.0]     # MinMax ì •ê·œí™”ëœ ë²”ìœ„
```

**ë°ì´í„° í•´ì„**:
```python
import pandas as pd

# ì˜ˆì¸¡ ë°ì´í„° ë¡œë“œ
forecast_df = pd.read_csv('tst_predictions/TEST1_forecast_20250524_123639.csv')

# ì¼ë³„ ì˜ˆì¸¡ í™•ì¸
day_0_prediction = forecast_df.iloc[0, 1:]  # ë‚´ì¼ ì˜ˆì¸¡ (87ê°œ íŠ¹ì„±)
day_9_prediction = forecast_df.iloc[9, 1:]  # 10ì¼ í›„ ì˜ˆì¸¡

# íŠ¹ì • ì§€í‘œ ì¶”ì„¸ ë¶„ì„
close_price_trend = forecast_df.iloc[:, 4]  # ì¢…ê°€ ì§€í‘œ (ê°€ì •)
rsi_trend = forecast_df.iloc[:, 16]         # RSI ì§€í‘œ (ê°€ì •)
```

#### **3. Prediction Summary (.txt íŒŒì¼)**

**ë‚´ìš© ì˜ˆì‹œ**:
```
TST Model Prediction Summary
Timestamp: 20250524_123646
Model: /path/to/tst_model_best_20250523_213809.pt
Number of tickers: 1
Tickers: AAPL

AAPL:
  Last data date: 2024-05-09 00:00:00
  Prediction type: rl_state
  RL state size: 256
  RL state mean: 0.0033      # ìƒíƒœ ë²¡í„° í‰ê· 
  RL state std: 0.0812       # ìƒíƒœ ë²¡í„° í‘œì¤€í¸ì°¨
```

### ê°•í™”í•™ìŠµ í†µí•© ì›Œí¬í”Œë¡œìš°

#### **1. ìƒíƒœ ë²¡í„° ìƒì„±**
```python
# predict.py ì‹¤í–‰ìœ¼ë¡œ RL ìƒíƒœ ìƒì„±
subprocess.run([
    'python', 'tst_model/predict.py', 
    '--ticker', 'AAPL', 
    '--mode', 'rl_state'
])

# ìƒì„±ëœ ìƒíƒœ ë²¡í„° ë¡œë“œ
rl_state = np.load('tst_predictions/AAPL_rl_state_latest.npy')
```

#### **2. RL ì—ì´ì „íŠ¸ ì˜ì‚¬ê²°ì •**
```python
from rl_agent import PPOAgent

# ì—ì´ì „íŠ¸ ë¡œë“œ
agent = PPOAgent.load('trained_models/ppo_agent.pkl')

# í–‰ë™ ê²°ì •
action, action_prob = agent.predict(rl_state)
action_mapping = {0: 'HOLD', 1: 'BUY', 2: 'SELL'}
recommendation = action_mapping[action]

print(f"Recommendation: {recommendation} (confidence: {action_prob:.3f})")
```

#### **3. ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸**
```python
def get_trading_recommendation(ticker):
    # 1. ìµœì‹  ë°ì´í„°ë¡œ ì˜ˆì¸¡ ì‹¤í–‰
    run_prediction(ticker)
    
    # 2. RL ìƒíƒœ ë²¡í„° ë¡œë“œ
    rl_state = load_latest_rl_state(ticker)
    
    # 3. RL ì—ì´ì „íŠ¸ ì˜ì‚¬ê²°ì •
    action = rl_agent.predict(rl_state)
    
    # 4. ì˜ˆì¸¡ ê²°ê³¼ì™€ ê²°í•©í•˜ì—¬ ìµœì¢… ì¡°ì–¸
    forecast = load_latest_forecast(ticker)
    final_advice = combine_rl_and_forecast(action, forecast)
    
    return final_advice
```

### ê¸°ìˆ ì  íŠ¹ì§•

#### **1. ë™ì  Feature í¬ê¸° ì¡°ì •**
```python
# ì‹¤ì œ ë°ì´í„°ì—ì„œ feature ìˆ˜ë¥¼ ìë™ ê°ì§€
data_info = prepare_data_for_prediction(data_path)
actual_input_size = len(data_info['feature_columns'])
model_config['input_size'] = actual_input_size  # 87ê°œë¡œ ìë™ ì¡°ì •
```

#### **2. ëª¨ë¸ í˜¸í™˜ì„± ê²€ì¦**
- í›ˆë ¨ëœ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ì™€ ì…ë ¥ í¬ê¸° ìë™ ë§¤ì¹­
- train.pyì™€ ë™ì¼í•œ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
- Feature engineering ë°©ì‹ í†µì¼ (synthetic news features)

#### **3. í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**
```python
# ìƒˆë¡œìš´ ì˜ˆì¸¡ ëª¨ë“œ ì¶”ê°€ ê°€ëŠ¥
def predict_with_tst_model(model, data, mode='rl_state'):
    if mode == 'rl_state':
        return model(data)  # 256D ë²¡í„°
    elif mode == 'forecast':
        return model.predict_future(data)  # 10Ã—87 ì˜ˆì¸¡
    elif mode == 'custom_analysis':
        return custom_analysis_function(model, data)
```

### ì„±ëŠ¥ íŠ¹ì„±

#### **ì²˜ë¦¬ ì†ë„**
- **RL State ìƒì„±**: ~50ms (ë‹¨ì¼ í‹°ì»¤, GPU)
- **Forecast ì˜ˆì¸¡**: ~100ms (ë‹¨ì¼ í‹°ì»¤, GPU)
- **ë°°ì¹˜ ì²˜ë¦¬**: ~200ms (32 í‹°ì»¤ ë™ì‹œ, GPU)

#### **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**
- **ì¶”ë¡  VRAM**: ~15MB (ë‹¨ì¼ ì˜ˆì¸¡)
- **CPU RAM**: ~100MB (ë°ì´í„° ì „ì²˜ë¦¬ í¬í•¨)
- **ì¶œë ¥ íŒŒì¼ í¬ê¸°**: RL state 1KB, Forecast 10KB

#### **ì •í™•ë„ ê²€ì¦**
```python
# ì˜ˆì¸¡ í’ˆì§ˆ í™•ì¸
def validate_predictions(ticker, actual_data, predicted_data):
    # RL ìƒíƒœ ë²¡í„°ì˜ ì¼ê´€ì„± í™•ì¸
    state_consistency = check_state_vector_stability(ticker)
    
    # ì˜ˆì¸¡ê°’ì˜ í•©ë¦¬ì„± í™•ì¸
    forecast_validity = validate_forecast_range(predicted_data)
    
    # ê³¼ê±° ì˜ˆì¸¡ê³¼ì˜ ì—°ì†ì„± í™•ì¸
    temporal_consistency = check_temporal_consistency(ticker)
    
    return {
        'state_quality': state_consistency,
        'forecast_quality': forecast_validity,
        'temporal_quality': temporal_consistency
    }
```

### ì‹¤ì „ í™œìš© ë°©ì•ˆ

#### **1. ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ë´‡**
```python
# ë§¤ ì‹œì¥ ì˜¤í”ˆ ì‹œ ì‹¤í–‰
def daily_market_analysis():
    for ticker in portfolio_tickers:
        # ì˜ˆì¸¡ ì‹¤í–‰
        run_prediction(ticker)
        
        # RL ì˜ì‚¬ê²°ì •
        recommendation = get_rl_recommendation(ticker)
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ì¡°ì •
        adjust_portfolio(ticker, recommendation)
```

#### **2. ë°±í…ŒìŠ¤íŒ… ì‹œìŠ¤í…œ**
```python
# ê³¼ê±° ë°ì´í„°ë¡œ ì˜ˆì¸¡ ì„±ëŠ¥ ê²€ì¦
def backtest_predictions(start_date, end_date):
    for date in date_range(start_date, end_date):
        # í•´ë‹¹ ì‹œì  ë°ì´í„°ë¡œ ì˜ˆì¸¡
        predictions = predict_at_date(date)
        
        # ì‹¤ì œ ê²°ê³¼ì™€ ë¹„êµ
        actual_results = get_actual_data(date + 10_days)
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
        accuracy = calculate_accuracy(predictions, actual_results)
        
        return accuracy_metrics
```

#### **3. ë‹¤ì¤‘ ì „ëµ í†µí•©**
```python
def multi_strategy_decision(ticker):
    # TST ì˜ˆì¸¡
    tst_prediction = get_tst_prediction(ticker)
    
    # RL ì¶”ì²œ
    rl_recommendation = get_rl_recommendation(ticker)
    
    # ê¸°ìˆ ì  ë¶„ì„
    ta_signals = get_technical_signals(ticker)
    
    # ê°ì„± ë¶„ì„
    sentiment_score = get_news_sentiment(ticker)
    
    # í†µí•© ì˜ì‚¬ê²°ì •
    final_decision = ensemble_decision([
        tst_prediction, rl_recommendation, 
        ta_signals, sentiment_score
    ])
    
    return final_decision
```

ì´ ì‹œìŠ¤í…œì„ í†µí•´ **ê³¼ê±° 60ì¼ì˜ ë³µì¡í•œ ì‹œì¥ ë°ì´í„°ë¥¼ 256ì°¨ì› ë²¡í„°ë¡œ ì••ì¶•**í•˜ì—¬ RL ì—ì´ì „íŠ¸ê°€ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµí•˜ê³  ì˜ì‚¬ê²°ì •í•  ìˆ˜ ìˆìœ¼ë©°, ë™ì‹œì— **ë¯¸ë˜ 10ì¼ê°„ì˜ ìƒì„¸í•œ ì˜ˆì¸¡**ì„ í†µí•´ ì‹œì¥ íŠ¸ë Œë“œë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## API í‚¤ ë° í™˜ê²½ ì„¤ì • ê°€ì´ë“œ

### ğŸ” ë³´ì•ˆ ì„¤ì • (API Keys Configuration)

ì´ í”„ë¡œì íŠ¸ëŠ” ì—¬ëŸ¬ ì™¸ë¶€ APIë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ API í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¼ê°í•œ ì •ë³´ë¥¼ git repositoryì—ì„œ ë¶„ë¦¬í–ˆìŠµë‹ˆë‹¤.

#### **1. ì´ˆê¸° ì„¤ì • (First Time Setup)**

```bash
# 1. í”„ë¡œì íŠ¸ í´ë¡ 
git clone <repository-url>
cd reinforcement_project-main

# 2. ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 3. í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ìƒì„±
cp .env.example .env

# 4. API í‚¤ ì„¤ì • (ë‹¤ìŒ ë‹¨ê³„ ì°¸ì¡°)
nano .env  # ë˜ëŠ” ì›í•˜ëŠ” ì—ë””í„° ì‚¬ìš©
```

#### **2. í•„ìˆ˜ API í‚¤ íšë“**

| API | ìš©ë„ | ë¬´ë£Œ í•œë„ | íšë“ ë°©ë²• |
|-----|------|-----------|-----------|
| **Alpha Vantage** | ì£¼ì‹ OHLCV ë°ì´í„° | 500 calls/day | [https://www.alphavantage.co/support/#api-key](https://www.alphavantage.co/support/#api-key) |
| **News API** | ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ìˆ˜ì§‘ | 1000 requests/day | [https://newsapi.org/register](https://newsapi.org/register) |
| **Quandl** (ì„ íƒ) | ì¶”ê°€ ê¸ˆìœµ ë°ì´í„° | 50 calls/day | [https://www.quandl.com/](https://www.quandl.com/) |

#### **3. .env íŒŒì¼ ì„¤ì •**

`.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•˜ì„¸ìš”:

```bash
# ===== API Keys =====
ALPHA_VANTAGE_API_KEY=your_alpha_vantage_key_here
NEWS_API_KEY=your_news_api_key_here
QUANDL_API_KEY=your_quandl_key_here

# ===== Model Configuration =====
DEFAULT_BATCH_SIZE=32
DEFAULT_CONTEXT_LENGTH=60
DEFAULT_PREDICTION_LENGTH=10

# ===== Trading Configuration =====
SUPPORTED_TICKERS=AAPL,GOOGL,MSFT,AMZN,TSLA,NVDA,META,NFLX
DEFAULT_INVESTMENT_AMOUNT=10000.0

# ===== Debug Mode =====
DEBUG_MODE=False
LOG_LEVEL=INFO
```

#### **4. ì„¤ì • ê²€ì¦**

```python
# ì„¤ì •ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
python -c "from config.settings import validate_api_keys; validate_api_keys()"

# ì¶œë ¥ ì˜ˆì‹œ:
# âœ… All required API keys are configured
```

#### **5. Git ì €ì¥ì†Œ ë³´ì•ˆ**

```bash
# .env íŒŒì¼ì´ gitì— ì¶”ê°€ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
git status

# ë‹¤ìŒì´ í‘œì‹œë˜ì–´ì•¼ í•¨:
# On branch main
# nothing to commit, working tree clean

# .env íŒŒì¼ì€ .gitignoreì— ì˜í•´ ìë™ìœ¼ë¡œ ì œì™¸ë¨
```

### ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡° ë° ì„¤ì • íŒŒì¼

```
reinforcement_project-main/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py              # í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì • (gitì— í¬í•¨)
â”‚   â””â”€â”€ settings_template.py     # ì„¤ì • í…œí”Œë¦¿ (ì°¸ê³ ìš©)
â”œâ”€â”€ .env                         # ì‹¤ì œ API í‚¤ë“¤ (gitì—ì„œ ì œì™¸)
â”œâ”€â”€ .env.example                 # í™˜ê²½ë³€ìˆ˜ í…œí”Œë¦¿ (gitì— í¬í•¨)
â”œâ”€â”€ .gitignore                   # ë¯¼ê°í•œ íŒŒì¼ë“¤ ì œì™¸ ì„¤ì •
â””â”€â”€ requirements.txt             # python-dotenv í¬í•¨
```

### ğŸ”§ ê³ ê¸‰ ì„¤ì • ì˜µì…˜

#### **í™˜ê²½ë³„ ì„¤ì •**

```bash
# ê°œë°œ í™˜ê²½
DEBUG_MODE=True
LOG_LEVEL=DEBUG

# í”„ë¡œë•ì…˜ í™˜ê²½
DEBUG_MODE=False
LOG_LEVEL=INFO
```

#### **ì„±ëŠ¥ íŠœë‹**

```bash
# GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•œ ê²½ìš°
DEFAULT_BATCH_SIZE=16
DEFAULT_CONTEXT_LENGTH=30

# ê³ ì„±ëŠ¥ GPU ì‚¬ìš© ì‹œ
DEFAULT_BATCH_SIZE=64
DEFAULT_CONTEXT_LENGTH=120
```

#### **ì»¤ìŠ¤í…€ ê²½ë¡œ ì„¤ì •**

```bash
# ëª¨ë¸ ì €ì¥ ê²½ë¡œ ë³€ê²½
TST_MODEL_PATH=/custom/path/to/models/
RL_AGENT_MODEL_PATH=/custom/path/to/agents/

# ë°ì´í„° ë””ë ‰í† ë¦¬ ë³€ê²½
DATA_DIR=/large/storage/data/
TST_PREDICTIONS_DIR=/fast/ssd/predictions/
```

### ğŸš¨ ë³´ì•ˆ ì£¼ì˜ì‚¬í•­

#### **âŒ ì ˆëŒ€ í•˜ì§€ ë§ ê²ƒ**
```bash
# API í‚¤ë¥¼ ì½”ë“œì— ì§ì ‘ í•˜ë“œì½”ë”©
ALPHA_VANTAGE_API_KEY = "abc123"  # ìœ„í—˜!

# .env íŒŒì¼ì„ gitì— ì»¤ë°‹
git add .env  # ì ˆëŒ€ ê¸ˆì§€!
```

#### **âœ… ê¶Œì¥ ì‚¬í•­**
```bash
# í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
export ALPHA_VANTAGE_API_KEY="your_key"
python your_script.py

# .env íŒŒì¼ ê¶Œí•œ ì„¤ì • (Linux/Mac)
chmod 600 .env

# API í‚¤ ì •ê¸° êµì²´ (ë³´ì•ˆ ê°•í™”)
```

### ğŸ” íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

#### **API í‚¤ ì—ëŸ¬**
```python
# ì—ëŸ¬: âš ï¸ Configuration Warning: Missing required API keys: ALPHA_VANTAGE_API_KEY

# í•´ê²°ë°©ë²•:
# 1. .env íŒŒì¼ ì¡´ì¬ í™•ì¸
# 2. API í‚¤ ê°’ í™•ì¸ (ê³µë°±, ë”°ì˜´í‘œ ì œê±°)
# 3. íŒŒì¼ ê¶Œí•œ í™•ì¸
```

#### **import ì—ëŸ¬**
```bash
# ì—ëŸ¬: ModuleNotFoundError: No module named 'dotenv'

# í•´ê²°ë°©ë²•:
pip install python-dotenv
```

#### **API í•œë„ ì´ˆê³¼**
```python
# Alpha Vantage: 500 calls/day ì œí•œ
# News API: 1000 requests/day ì œí•œ

# í•´ê²°ë°©ë²•:
# 1. ì—¬ëŸ¬ API í‚¤ ë¡œí…Œì´ì…˜ ì‚¬ìš©
# 2. ìºì‹± êµ¬í˜„ìœ¼ë¡œ API í˜¸ì¶œ ìµœì†Œí™”
# 3. í”„ë¦¬ë¯¸ì—„ í”Œëœ ì—…ê·¸ë ˆì´ë“œ ê³ ë ¤
```

### ğŸ“‹ ì„¤ì • ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `.env` íŒŒì¼ ìƒì„± ì™„ë£Œ
- [ ] ëª¨ë“  í•„ìˆ˜ API í‚¤ ì„¤ì • ì™„ë£Œ
- [ ] `python-dotenv` ì„¤ì¹˜ ì™„ë£Œ
- [ ] ì„¤ì • ê²€ì¦ ì„±ê³µ (`validate_api_keys()`)
- [ ] `.env` íŒŒì¼ì´ gitì— ì¶”ê°€ë˜ì§€ ì•ŠìŒ í™•ì¸
- [ ] í”„ë¡œì íŠ¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ

ì´ ì„¤ì •ì„ ì™„ë£Œí•˜ë©´ API í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•˜ë©´ì„œ í”„ë¡œì íŠ¸ë¥¼ git repositoryì— ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---



