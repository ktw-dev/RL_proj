# main.py: Entry point of the stock trading application. 
# 05-24-2025 19:25
"""
[ì…ë ¥ ì •ë³´]
1. ì¢…ëª© (ticker)
2. ì£¼ì‹ ë³´ìœ  ì—¬ë¶€
  2-1. ë³´ìœ  ì¤‘ì¸ ê²½ìš°: ë³´ìœ  ìˆ˜ëŸ‰(num_of_share), í‰ë‹¨ê°€(avg_price)
3. í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ íˆ¬ì ê¸ˆì•¡ (bullet)
4. ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì•¡ì…˜ (ë§¤ìˆ˜: 1, ë§¤ë„: 0) ë° í•´ë‹¹ ì˜ì‚¬ì˜ ê°•ë„(ê°€ì¤‘ì¹˜)
5. ì„ íƒí•  ì—ì´ì „íŠ¸: PPO('bob') ë˜ëŠ” SAC('sara')

[ë‚´ë¶€ ì²˜ë¦¬ ê³¼ì •]
1. ì…ë ¥ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ticker, num_of_share, bullet, action_intention ë“± í•µì‹¬ ìƒíƒœ ë³€ìˆ˜ ì •ë¦¬
2. ìµœê·¼ 7ì¼ ê°„ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘ â†’ ê°ì„± ë¶„ì„ ìˆ˜í–‰
   - news_fetcher.py â†’ news_processor.py íŒŒì´í”„ë¼ì¸
   - ì¶œë ¥: ì¼ë³„ ê°ì„± ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
3. ê¸°ìˆ ì  ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘ (OHLCV + ì§€í‘œ)
   - ta_fetcher.py í†µí•´ 7ì¼ì¹˜ OHLCV ë° ê¸°ìˆ  ì§€í‘œ ìƒì„±
4. TST ê¸°ë°˜ ê°€ê²© ì˜ˆì¸¡ ìˆ˜í–‰
   - ì…ë ¥: OHLCV + ê¸°ìˆ  ì§€í‘œ + ê°ì„± ì ìˆ˜
   - ì¶œë ¥: í–¥í›„ ê°€ê²© ë³€í™” ì˜ˆì¸¡ê°’
5. ìƒíƒœ(state) ë²¡í„° êµ¬ì„±
   - êµ¬ì„± ìš”ì†Œ: ì˜ˆì¸¡ê°’ + ë³´ìœ  ì •ë³´ + ê°ì„± ì ìˆ˜ + ì‚¬ìš© ê°€ëŠ¥ ìê¸ˆ ë“±
6. ì„ íƒëœ ì—ì´ì „íŠ¸(PPO/SAC)ë¥¼ í†µí•´ ìµœì  ì•¡ì…˜ ë„ì¶œ
   - action = agent.predict(state)
7. ìµœì¢… ì¶œë ¥
   - ì¢…ëª©ì˜ í–¥í›„ ì˜ˆì¸¡ ë°©í–¥ (ìƒìŠ¹/í•˜ë½)
   - ì¶”ì²œ ì•¡ì…˜ (ë§¤ìˆ˜/ë§¤ë„/ê´€ë§)
   - ê¶Œì¥ ê°€ê²©ëŒ€ (ì˜ˆ: Xì› ì´í•˜ì— ë§¤ìˆ˜, Yì› ì´ìƒì— ë§¤ë„ ë“±)

[ë¹„ê³ ]
- ì „ì²´ ë¡œì§ì€ main.pyì—ì„œ í†µí•©ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë©°, ì‚¬ìš©ì ì…ë ¥ë¶€í„° ìµœì¢… íŠ¸ë ˆì´ë”© ê°€ì´ë“œ ì¶œë ¥ê¹Œì§€ ìë™í™”ë¨.
"""

import sys
from pathlib import Path
import pandas as pd # For type hinting and potential DataFrame manipulation
from datetime import datetime, timedelta, timezone
import os
import glob

# Add the project root directory to sys.path
project_root = Path(__file__).resolve().parent
sys.path.append(str(project_root))

# --- Actual Module Imports ---
from data_collection.news_analyzer import fetch_and_analyze_recent_news
from feature_engineering.news_processor import aggregate_daily_sentiment_features, is_us_business_day
from data_collection.ta_fetcher import fetch_recent_ohlcv_for_inference
from feature_engineering.ta_calculator_now import calculate_current_technical_indicators
from feature_engineering.ta_calculator import calculate_technical_indicators
from tst_model.model import TSTModel
from config.tickers import SUPPORTED_TICKERS
from rl_agent.ppo_agent import PPOAgent
from rl_agent.sac_agent import SACAgent
import torch
import torch.nn as nn
import numpy as np
from sklearn.preprocessing import MinMaxScaler

# --- TST Model Configuration (matching train.py and predict_realtime.py) ---
DEFAULT_MODEL_CONFIG = {
    'input_size': 87,  # 80 TA + 7 News features
    'prediction_length': 10,
    'context_length': 60,    # TST model context length
    'n_layer': 4,
    'n_head': 8,
    'd_model': 128,
    'rl_state_size': 256,
    'distribution_output': "normal", 
    'loss': "nll",             
    'num_parallel_samples': 100
}

# --- Constants for Data Fetching/Processing ---
TA_LOOKBACK_PERIOD = 60  # Days of historical data needed for TA calculation (e.g., for 50-day SMA)
TST_MODEL_DIR = os.path.join(project_root, 'tst_model_output')
RL_MODEL_DIR = os.path.join(project_root, 'rl_model_output') # New constant for RL models

# --- Mock Agent Classes (to be replaced with real implementations later) ---
# class MockPPOAgent:
#     def predict_action(self, state_vector: dict):
#         print(f"[Mock PPO] Analyzing state: price={state_vector.get('current_price')}, sentiment={state_vector.get('market_sentiment_score'):.3f}")
#         # Simple mock logic based on sentiment and price trend
#         sentiment = state_vector.get('market_sentiment_score', 0.0)
#         tst_direction = state_vector.get('tst_predicted_direction', 'UNKNOWN')
#         current_price = state_vector.get('current_price', 0)
        
#         if tst_direction == "UP" and sentiment > 0.1:
#             action = "BUY"
#             reason = "Positive TST prediction and sentiment"
#             target_price = current_price * 1.02 if current_price else None
#         elif tst_direction == "DOWN" or sentiment < -0.1:
#             action = "SELL"
#             reason = "Negative TST prediction or sentiment"
#             target_price = current_price * 0.98 if current_price else None
#         else:
#             action = "HOLD"
#             reason = "Uncertain market conditions"
#             target_price = current_price
            
#         return {"action": action, "reason": reason, "target_price": target_price}

# class MockSACAgent:
#     def predict_action(self, state_vector: dict):
#         print(f"[Mock SAC] Analyzing state: price={state_vector.get('current_price')}, sentiment={state_vector.get('market_sentiment_score'):.3f}")
#         # Mock SAC with slightly different logic
#         sentiment = state_vector.get('market_sentiment_score', 0.0)
#         confidence = state_vector.get('tst_confidence', 0.0)
#         current_price = state_vector.get('current_price', 0)
        
#         if confidence > 0.7 and sentiment > 0.05:
#             action = "BUY"
#             reason = "High confidence TST prediction with positive sentiment"
#             target_price = current_price * 1.015 if current_price else None
#         elif confidence > 0.7 and sentiment < -0.05:
#             action = "SELL" 
#             reason = "High confidence TST prediction with negative sentiment"
#             target_price = current_price * 0.985 if current_price else None
#         else:
#             action = "HOLD"
#             reason = "Low confidence or neutral sentiment"
#             target_price = current_price
            
#         return {"action": action, "reason": reason, "target_price": target_price}

# --- Helper Function Definitions --- 

def get_user_input():
    """Collects necessary input from the user through CLI."""
    print("\n--- 1. Collecting User Input ---")

    # ì§€ì›í•˜ëŠ” ì¢…ëª©
    print(f"ì§€ì›í•˜ëŠ” ì¢…ëª©: {SUPPORTED_TICKERS}")
    
    # 1. ì¢…ëª© ì…ë ¥
    ticker = input(f"ì¢…ëª©ì„ ì…ë ¥í•˜ì„¸ìš” ({', '.join(SUPPORTED_TICKERS)} ì¤‘ ì„ íƒ): ").strip().upper()
    if ticker not in SUPPORTED_TICKERS:
        raise ValueError(f"Ticker {ticker} is not supported.")

    # 2. ì£¼ì‹ ë³´ìœ  ì—¬ë¶€
    has_shares_input = input("í•´ë‹¹ ì¢…ëª©ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
    has_shares = has_shares_input == "y"

    num_shares = 0
    avg_price = 0.0
    if has_shares:
        num_shares = int(input("ë³´ìœ  ì£¼ì‹ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”: "))
        avg_price = float(input("ë³´ìœ  ì£¼ì‹ì˜ í‰ë‹¨ê°€ë¥¼ ì…ë ¥í•˜ì„¸ìš”: "))

    # 3. í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ íˆ¬ìê¸ˆ
    bullet = float(input("í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ íˆ¬ì ê¸ˆì•¡ì„ ì…ë ¥í•˜ì„¸ìš”: "))

    # 4. ì‚¬ìš©ì ì˜í–¥ (ë§¤ìˆ˜/ë§¤ë„)
    action_str = input("ì›í•˜ëŠ” ì•¡ì…˜ì„ ì…ë ¥í•˜ì„¸ìš” (BUY/SELL): ").strip().upper()
    strength = float(input("ì´ ì•¡ì…˜ì„ ì–¼ë§ˆë‚˜ ì›í•˜ì‹­ë‹ˆê¹Œ? (0.0 ~ 1.0): "))
    if action_str not in ["BUY", "SELL"]:
        raise ValueError("Action must be BUY or SELL.")

    user_action_intention = {"action": action_str, "strength": strength}

    # 5. ì—ì´ì „íŠ¸ ì„ íƒ
    agent_choice = input("ì‚¬ìš©í•  ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (PPO/SAC): ").strip().upper()
    if agent_choice not in ["PPO", "SAC"]:
        raise ValueError("Agent must be PPO or SAC.")

    user_input = {
        "ticker": ticker,
        "has_shares": has_shares,
        "num_shares": num_shares,
        "avg_price": avg_price,
        "bullet": bullet,
        "user_action_intention": user_action_intention,
        "agent_choice": agent_choice
    }

    print(f"\n[ì…ë ¥ í™•ì¸] {user_input}")
    return user_input

def initialize_state_variables(user_input: dict):
    """Processes raw user input into structured state variables.
    Returns a dictionary of core state variables.
    """
    print("\n--- 2. Initializing State Variables ---")
    state_vars = {
        "ticker": user_input["ticker"],
        "holdings_info": {
            "has_shares": user_input["has_shares"],
            "num_shares": user_input.get("num_shares", 0),
            "avg_price": user_input.get("avg_price", 0.0)
        },
        "available_cash": user_input["bullet"],
        "user_intention": user_input["user_action_intention"],
        "chosen_agent": user_input["agent_choice"]
    }
    print(f"Initialized State: {state_vars}")
    return state_vars

def collect_realtime_ta_data(ticker: str, business_days: int = 7, lookback_period: int = 60) -> pd.DataFrame:
    """
    ì‹¤ì‹œê°„ìœ¼ë¡œ TA ë°ì´í„° ìˆ˜ì§‘ (ta_fetcher.py ì‚¬ìš©)
    
    Args:
        ticker (str): ì¢…ëª© ì½”ë“œ
        business_days (int): ë¶„ì„ ëŒ€ìƒ ì˜ì—…ì¼ ìˆ˜
        lookback_period (int): TST ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì¶”ê°€ ì¼ìˆ˜
        
    Returns:
        pd.DataFrame: TA íŠ¹ì„±ì´ ê³„ì‚°ëœ ë°ì´í„°í”„ë ˆì„
    """
    print(f"=== Collecting real-time TA data for {ticker} ===")
    print(f"Target: {business_days} business days + {lookback_period} days context")
    
    # ta_fetcherì˜ fetch_recent_ohlcv_for_inference ì‚¬ìš©
    ohlcv_df = fetch_recent_ohlcv_for_inference(
        ticker_symbol=ticker,
        business_days=business_days,
        lookback_period=lookback_period
    )
    
    if ohlcv_df.empty:
        print(f"âŒ No OHLCV data collected for {ticker}")
        return pd.DataFrame()
    
    print(f"âœ… OHLCV data collected: {len(ohlcv_df)} rows")
    print(f"Date range: {ohlcv_df['Date'].iloc[0]} to {ohlcv_df['Date'].iloc[-1]}")
    
    # DataFrameì„ TA ê³„ì‚°ì— ë§ëŠ” í˜•íƒœë¡œ ì¤€ë¹„
    try:
        # Dateë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì • (TA ê³„ì‚°ì— í•„ìš”)
        ohlcv_df['Date'] = pd.to_datetime(ohlcv_df['Date'])
        ohlcv_df.set_index('Date', inplace=True)
        
        # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        print("Calculating technical indicators...")
        ta_df = calculate_technical_indicators(ohlcv_df.copy(), include_ohlcv=True)
        
        if ta_df.empty:
            print(f"âŒ Failed to calculate technical indicators for {ticker}")
            return pd.DataFrame()
        
        # Dateë¥¼ ë‹¤ì‹œ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
        ta_df.reset_index(inplace=True)
        ta_df['Date'] = ta_df['Date'].dt.strftime('%Y-%m-%d')
        
        print(f"âœ… Technical indicators calculated: {len(ta_df)} rows, {len(ta_df.columns)} features")
        return ta_df
        
    except Exception as e:
        print(f"âŒ Error calculating TA for {ticker}: {e}")
        return pd.DataFrame()

def collect_realtime_news_data(ticker: str, analysis_days: int = 7) -> pd.DataFrame:
    """
    ì‹¤ì‹œê°„ìœ¼ë¡œ ë‰´ìŠ¤ ê°ì„± ë°ì´í„° ìˆ˜ì§‘ (news_analyzer.py + news_processor.py ì‚¬ìš©)
    
    Args:
        ticker (str): ì¢…ëª© ì½”ë“œ
        analysis_days (int): ë¶„ì„ ëŒ€ìƒ ì¼ìˆ˜
        
    Returns:
        pd.DataFrame: ì¼ë³„ ë‰´ìŠ¤ ê°ì„± íŠ¹ì„± ë°ì´í„°í”„ë ˆì„
    """
    print(f"=== Collecting real-time news sentiment for {ticker} ===")
    print(f"Target: {analysis_days} days of news analysis")
    
    try:
        # ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ê°ì„± ë¶„ì„
        analyzed_news_df = fetch_and_analyze_recent_news(ticker)
        
        if analyzed_news_df.empty:
            print(f"No news found for {ticker}, creating neutral sentiment")
            return create_neutral_news_sentiment(analysis_days)
        
        print(f"âœ… News collected: {len(analyzed_news_df)} articles")
        
        # ì¼ë³„ ê°ì„± íŠ¹ì„± ì§‘ê³„
        daily_sentiment_df = aggregate_daily_sentiment_features(analyzed_news_df, ticker)
        
        if daily_sentiment_df.empty:
            print(f"Failed to process news sentiment for {ticker}")
            return create_neutral_news_sentiment(analysis_days)
        
        print(f"âœ… News sentiment processed: {len(daily_sentiment_df)} days")
        return daily_sentiment_df
        
    except Exception as e:
        print(f"âŒ Error collecting news for {ticker}: {e}")
        return create_neutral_news_sentiment(analysis_days)

def create_neutral_news_sentiment(days: int) -> pd.DataFrame:
    """ë‰´ìŠ¤ê°€ ì—†ì„ ë•Œ ì¤‘ë¦½ ê°ì„± ë°ì´í„° ìƒì„±"""
    print(f"Creating neutral sentiment data for {days} days")
    
    end_date = datetime.now().date()
    start_date = end_date - timedelta(days=days-1)
    date_range = pd.date_range(start=start_date, end=end_date, freq='D')
    
    neutral_data = {
        'date': date_range,
        'avg_sentiment_positive': 0.0,
        'avg_sentiment_negative': 0.0,
        'avg_sentiment_neutral': 1.0,
        'news_count': 0,
        'weekend_effect_positive': 0.0,
        'weekend_effect_negative': 0.0,
        'weekend_effect_neutral': 0.0,
    }
    
    df = pd.DataFrame(neutral_data)
    df.set_index('date', inplace=True)
    return df

def merge_ta_and_news_data(ta_df: pd.DataFrame, news_df: pd.DataFrame, ticker: str) -> pd.DataFrame:
    """
    TA ë°ì´í„°ì™€ ë‰´ìŠ¤ ê°ì„± ë°ì´í„°ë¥¼ ë³‘í•©í•˜ì—¬ 87ê°œ íŠ¹ì„± ë°ì´í„° ìƒì„±
    
    Args:
        ta_df (pd.DataFrame): TA íŠ¹ì„± ë°ì´í„°
        news_df (pd.DataFrame): ë‰´ìŠ¤ ê°ì„± ë°ì´í„°
        ticker (str): ì¢…ëª© ì½”ë“œ
        
    Returns:
        pd.DataFrame: ë³‘í•©ëœ 87ê°œ íŠ¹ì„± ë°ì´í„°
    """
    print(f"=== Merging TA and News data for {ticker} ===")
    
    if ta_df.empty:
        print(f"âŒ No TA data to merge for {ticker}")
        return pd.DataFrame()
    
    # TA ë°ì´í„° ì¤€ë¹„
    ta_df_copy = ta_df.copy()
    ta_df_copy['Date'] = pd.to_datetime(ta_df_copy['Date'])
    ta_df_copy['date'] = ta_df_copy['Date'].dt.date
    
    # ë‰´ìŠ¤ ë°ì´í„° ì¤€ë¹„
    if news_df.empty:
        print("No news data, creating neutral sentiment for all TA dates")
        # TA ë°ì´í„°ì˜ ëª¨ë“  ë‚ ì§œì— ëŒ€í•´ ì¤‘ë¦½ ê°ì„± ìƒì„±
        unique_dates = ta_df_copy['date'].unique()
        news_data = {
            'date': unique_dates,
            'avg_sentiment_positive': 0.0,
            'avg_sentiment_negative': 0.0,
            'avg_sentiment_neutral': 1.0,
            'news_count': 0,
            'weekend_effect_positive': 0.0,
            'weekend_effect_negative': 0.0,
            'weekend_effect_neutral': 0.0,
        }
        news_df = pd.DataFrame(news_data)
        news_df.set_index('date', inplace=True)
    
    # ë‰´ìŠ¤ ë°ì´í„° ì¸ë±ìŠ¤ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
    news_df_copy = news_df.reset_index()
    
    # ë‚ ì§œ íƒ€ì… í†µì¼ (object íƒ€ì…ìœ¼ë¡œ ë³€í™˜)
    ta_df_copy['date'] = ta_df_copy['date'].astype(str)
    if 'date' in news_df_copy.columns:
        news_df_copy['date'] = pd.to_datetime(news_df_copy['date']).dt.date.astype(str)
    
    # ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
    merged_df = pd.merge(ta_df_copy, news_df_copy, on='date', how='left')
    
    # ë‰´ìŠ¤ íŠ¹ì„±ì´ ì—†ëŠ” ë‚ ì§œëŠ” ì¤‘ë¦½ê°’ìœ¼ë¡œ ì±„ì›€
    news_features = ['avg_sentiment_positive', 'avg_sentiment_negative', 'avg_sentiment_neutral',
                    'news_count', 'weekend_effect_positive', 'weekend_effect_negative', 'weekend_effect_neutral']
    
    for feature in news_features:
        if feature not in merged_df.columns:
            if 'neutral' in feature:
                merged_df[feature] = 1.0
            else:
                merged_df[feature] = 0.0
        else:
            if 'neutral' in feature:
                merged_df[feature].fillna(1.0, inplace=True)
            else:
                merged_df[feature].fillna(0.0, inplace=True)
    
    # Ticker ì»¬ëŸ¼ ì¶”ê°€
    merged_df['Ticker'] = ticker
    
    # ìµœì¢… ì •ë¦¬
    merged_df = merged_df.drop(['date'], axis=1)
    merged_df = merged_df.sort_values('Date')
    
    print(f"âœ… Data merged successfully: {len(merged_df)} rows, {len(merged_df.columns)} columns")
    
    # 87ê°œ íŠ¹ì„± í™•ì¸
    numeric_cols = merged_df.select_dtypes(include=['number']).columns.tolist()
    # print(f"Numeric features: {len(numeric_cols)} (target: 87)") # Reduced verbosity
    
    return merged_df

def load_latest_tst_model(model_dir: str, model_config: dict, device: torch.device):
    """í›ˆë ¨ëœ TST ëª¨ë¸ ë¡œë“œ"""
    model_pattern = os.path.join(model_dir, "tst_model_best_*.pt")
    model_files = glob.glob(model_pattern)
    
    if not model_files:
        raise FileNotFoundError(f"No trained models found in {model_dir}")
    
    latest_model_path = max(model_files, key=os.path.getmtime)
    print(f"Loading TST model from: {latest_model_path}")
    
    model = TSTModel(config_dict=model_config).to(device)
    checkpoint = torch.load(latest_model_path, map_location=device)
    model.load_state_dict(checkpoint)
    model.eval()
    
    print(f"TST Model loaded successfully. Parameters: {sum(p.numel() for p in model.parameters()):,}")
    return model, latest_model_path

def load_latest_rl_agent(agent_type: str, model_base_dir: str, device: torch.device, state_dim: int = 259):
    """Loads the latest trained RL agent (PPO or SAC)."""
    print(f"--- Loading latest RL agent: {agent_type} ---")
    agent_name_pattern = f"{agent_type.lower()}_agent_*"
    search_pattern = os.path.join(model_base_dir, agent_name_pattern)
    
    run_dirs = [d for d in glob.glob(search_pattern) if os.path.isdir(d)]
    if not run_dirs:
        print(f"Warning: No training run directories found for {agent_type} in {model_base_dir}")
        return None
        
    latest_run_dir = max(run_dirs, key=os.path.getmtime)
    print(f"Found latest run directory: {latest_run_dir}")
    
    best_model_pattern = os.path.join(latest_run_dir, f"{agent_type.lower()}_agent_*_best_model.pt")
    model_files = glob.glob(best_model_pattern)
    
    if not model_files:
        print(f"Warning: No best model file found in {latest_run_dir} matching pattern {best_model_pattern}")
        return None
    
    latest_model_path = model_files[0] # Should ideally be only one best model
    print(f"Loading RL model from: {latest_model_path}")
    
    try:
        if agent_type == "PPO":
            agent = PPOAgent(state_dim=state_dim)
            checkpoint = torch.load(latest_model_path, map_location=device)
            agent.actor.load_state_dict(checkpoint['actor_state_dict'])
            agent.critic.load_state_dict(checkpoint['critic_state_dict'])
            # Ensure actor_old is also initialized if needed for some PPO versions, though not strictly for predict_action
            agent.actor_old.load_state_dict(agent.actor.state_dict())
            agent.actor.to(device)
            agent.critic.to(device)
            agent.actor_old.to(device)
            agent.actor.eval()
            agent.critic.eval()
            agent.actor_old.eval()
        elif agent_type == "SAC":
            agent = SACAgent(state_dim=state_dim)
            checkpoint = torch.load(latest_model_path, map_location=device)
            agent.policy_net.load_state_dict(checkpoint['policy_net_state_dict'])
            agent.q_net1.load_state_dict(checkpoint['q_net1_state_dict'])
            agent.q_net2.load_state_dict(checkpoint['q_net2_state_dict'])
            # Value net and target value net might not always be in 'best_model' if only actor/critic were saved for simplicity
            if 'value_net_state_dict' in checkpoint:
                agent.value_net.load_state_dict(checkpoint['value_net_state_dict'])
            if 'target_value_net_state_dict' in checkpoint:
                agent.target_value_net.load_state_dict(checkpoint['target_value_net_state_dict'])
            agent.policy_net.to(device)
            agent.q_net1.to(device)
            agent.q_net2.to(device)
            agent.value_net.to(device)
            agent.target_value_net.to(device)
            agent.policy_net.eval()
            agent.q_net1.eval()
            agent.q_net2.eval()
            agent.value_net.eval()
            agent.target_value_net.eval()
        else:
            raise ValueError(f"Unsupported agent type: {agent_type}")
            
        print(f"{agent_type} agent loaded successfully from {latest_model_path}")
        return agent
        
    except Exception as e:
        print(f"Error loading RL agent {agent_type} from {latest_model_path}: {e}")
        import traceback
        traceback.print_exc()
        return None

def predict_price_with_tst_model(technical_data: pd.DataFrame, daily_sentiment: pd.Series, ticker: str):
    """Predicts future price movement using the TST model.
    Input: TA data and daily sentiment scores.
    Returns: A dictionary with price prediction details including RL state.
    """
    print("\n--- 5. Predicting Price with TST Model ---")
    
    if technical_data.empty:
        print("Skipping TST prediction due to missing technical data.")
        return {"predicted_direction": "UNKNOWN", "confidence": 0.0, "rl_state": None}

    try:
        # Setup device
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # 1. TA ë°ì´í„°ì™€ ë‰´ìŠ¤ ë°ì´í„° ë³‘í•©í•˜ì—¬ 87ê°œ íŠ¹ì„± ìƒì„±
        # technical_dataë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ (ì¸ë±ìŠ¤ê°€ dateì´ë¯€ë¡œ)
        ta_df = technical_data.reset_index()
        ta_df['Date'] = pd.to_datetime(ta_df['Date'])
        
        # ë‰´ìŠ¤ ê°ì„±ì„ ëª¨ë“  TA ë‚ ì§œì— ëŒ€í•´ í™•ì¥
        if not daily_sentiment.empty:
            # ì›ë³¸ ë‰´ìŠ¤ ê°ì„± ë°ì´í„°
            original_sentiment = daily_sentiment.copy()
            # TA ë°ì´í„°ì˜ ëª¨ë“  ë‚ ì§œì— ëŒ€í•´ ë‰´ìŠ¤ ê°ì„± í™•ì¥
            all_dates = pd.to_datetime(ta_df['Date']).dt.date
            extended_sentiment = pd.Series(index=all_dates, dtype=float)
            
            # ë‰´ìŠ¤ê°€ ìˆëŠ” ë‚ ì§œëŠ” ì‹¤ì œ ê°’ ì‚¬ìš©, ì—†ëŠ” ë‚ ì§œëŠ” 0.0 ì‚¬ìš©
            for date in all_dates:
                if date in original_sentiment.index:
                    extended_sentiment[date] = original_sentiment[date]
                else:
                    extended_sentiment[date] = 0.0
            
            # DataFrameìœ¼ë¡œ ë³€í™˜
            news_df = pd.DataFrame({
                'date': extended_sentiment.index,
                'avg_sentiment_positive': np.where(extended_sentiment > 0, extended_sentiment, 0),
                'avg_sentiment_negative': np.where(extended_sentiment < 0, -extended_sentiment, 0),
                'avg_sentiment_neutral': np.where(extended_sentiment == 0, 1.0, 0.0),
                'news_count': np.where(extended_sentiment != 0, 1, 0),
                'weekend_effect_positive': 0.0,
                'weekend_effect_negative': 0.0,
                'weekend_effect_neutral': 0.0,
            })
            news_df.set_index('date', inplace=True)
        else:
            # ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ëª¨ë“  TA ë‚ ì§œì— ëŒ€í•´ ì¤‘ë¦½ ìƒì„±
            all_dates = pd.to_datetime(ta_df['Date']).dt.date
            news_df = pd.DataFrame({
                'date': all_dates,
                'avg_sentiment_positive': 0.0,
                'avg_sentiment_negative': 0.0,
                'avg_sentiment_neutral': 1.0,
                'news_count': 0,
                'weekend_effect_positive': 0.0,
                'weekend_effect_negative': 0.0,
                'weekend_effect_neutral': 0.0,
            })
            news_df.set_index('date', inplace=True)
        
        # ë°ì´í„° ë³‘í•©
        combined_df = merge_ta_and_news_data(ta_df, news_df, ticker)
        
        if combined_df.empty:
            print("Failed to merge TA and news data")
            return {"predicted_direction": "UNKNOWN", "confidence": 0.0, "rl_state": None}
        
        # 2. ëª¨ë¸ ì„¤ì • ë° ë¡œë“œ
        model_config = DEFAULT_MODEL_CONFIG.copy()
        numeric_cols = combined_df.select_dtypes(include=['number']).columns.tolist()
        model_config['input_size'] = len(numeric_cols)
        
        print(f"Loading TST model with input_size: {model_config['input_size']}")
        model, model_path = load_latest_tst_model(TST_MODEL_DIR, model_config, device)
        
        # 3. ë°ì´í„° ì „ì²˜ë¦¬
        combined_df['Date'] = pd.to_datetime(combined_df['Date'])
        combined_df.set_index(['Ticker', 'Date'], inplace=True)
        combined_df.sort_index(inplace=True)
        
        # ìŠ¤ì¼€ì¼ë§
        scaler = MinMaxScaler()
        scaled_values = scaler.fit_transform(combined_df[numeric_cols])
        scaled_df = pd.DataFrame(scaled_values, index=combined_df.index, columns=numeric_cols)
        
        # 4. ì˜ˆì¸¡ ì‹œí€€ìŠ¤ ìƒì„± (ìµœê·¼ 60ì¼ ì‚¬ìš©)
        ticker_data = scaled_df.values
        context_length = model_config['context_length']
        
        if len(ticker_data) < context_length:
            print(f"Insufficient data for TST prediction ({len(ticker_data)} < {context_length})")
            return {"predicted_direction": "UNKNOWN", "confidence": 0.0, "rl_state": None}
        
        # ìµœê·¼ context_length ë°ì´í„° ì‚¬ìš©
        sequence = ticker_data[-context_length:]
        sequence_tensor = torch.FloatTensor(sequence).unsqueeze(0).to(device)
        
        # 5. ì •êµí•œ ì˜ˆì¸¡ ë° ì‹ ë¢°ë„ ê³„ì‚°
        with torch.no_grad():
            # 5.1. RL State ìƒì„±
            rl_state = model(past_values=sequence_tensor)
            rl_state_numpy = rl_state.cpu().numpy().squeeze()
            
            # 5.2. ì‹¤ì œ ì£¼ê°€ ì˜ˆì¸¡ (10ì¼ í›„)
            future_predictions = model.predict_future(sequence_tensor, num_steps=10)
            future_predictions_numpy = future_predictions.cpu().numpy().squeeze()
            
            # 5.3. ë‹¤ì¤‘ ìƒ˜í”Œë§ì„ í†µí•œ ë¶ˆí™•ì‹¤ì„± ì¶”ì • (Monte Carlo)
            mc_samples = 20  # Monte Carlo ìƒ˜í”Œ ìˆ˜
            rl_states_mc = []
            price_predictions_mc = []
            
            # Dropoutì„ í™œì„±í™”í•˜ì—¬ ë‹¤ì–‘í•œ ì˜ˆì¸¡ ìƒì„±
            model.train()  # Dropout í™œì„±í™”
            for _ in range(mc_samples):
                # with torch.no_grad() ì œê±°í•˜ì—¬ dropoutì´ ì‹¤ì œë¡œ ì‘ë™í•˜ë„ë¡ í•¨
                mc_rl_state = model(past_values=sequence_tensor)
                mc_price_pred = model.predict_future(sequence_tensor, num_steps=10)
                rl_states_mc.append(mc_rl_state.detach().cpu().numpy().squeeze())
                price_predictions_mc.append(mc_price_pred.detach().cpu().numpy().squeeze())
            model.eval()  # ë‹¤ì‹œ eval ëª¨ë“œë¡œ
            
            # 5.4. í†µê³„ ë¶„ì„
            rl_state_mean = np.mean(rl_state_numpy)
            rl_state_std = np.std(rl_state_numpy)
            
            # Monte Carlo ìƒ˜í”Œë“¤ì˜ ë¶„ì‚° ê³„ì‚°
            mc_rl_states = np.array(rl_states_mc)
            mc_price_preds = np.array(price_predictions_mc)
            
            mc_rl_mean_var = np.var([np.mean(sample) for sample in mc_rl_states])
            mc_price_var = np.var([np.mean(sample[:, 0]) for sample in mc_price_preds])  # Close price ë³€ë™ì„±
            
            # 5.5. ì£¼ê°€ ë³€í™”ìœ¨ ì˜ˆì¸¡
            current_price = scaled_df.iloc[-1, 0]  # ë§ˆì§€ë§‰ Close price (scaled)
            predicted_price = future_predictions_numpy[0, 0]  # ì²« ë²ˆì§¸ ì˜ˆì¸¡ Close price
            price_change_rate = (predicted_price - current_price) / current_price
            
            # 5.6. ì •êµí•œ ë°©í–¥ ì˜ˆì¸¡
            direction_signals = []
            confidence_factors = []
            
            # Signal 1: RL State ê¸°ë°˜
            if rl_state_mean > 0.05:
                direction_signals.append("UP")
                confidence_factors.append(min(0.4, abs(rl_state_mean) * 4))
            elif rl_state_mean < -0.05:
                direction_signals.append("DOWN")
                confidence_factors.append(min(0.4, abs(rl_state_mean) * 4))
            else:
                direction_signals.append("SIDEWAYS")
                confidence_factors.append(0.1)
            
            # Signal 2: ì£¼ê°€ ì˜ˆì¸¡ ê¸°ë°˜
            if price_change_rate > 0.02:  # 2% ì´ìƒ ìƒìŠ¹
                direction_signals.append("UP")
                confidence_factors.append(min(0.4, abs(price_change_rate) * 10))
            elif price_change_rate < -0.02:  # 2% ì´ìƒ í•˜ë½
                direction_signals.append("DOWN")
                confidence_factors.append(min(0.4, abs(price_change_rate) * 10))
            else:
                direction_signals.append("SIDEWAYS")
                confidence_factors.append(0.1)
            
            # Signal 3: Monte Carlo ë¶ˆí™•ì‹¤ì„± ê¸°ë°˜
            uncertainty_penalty = min(0.3, mc_rl_mean_var * 1000 + mc_price_var * 100)
            
            # 5.7. ìµœì¢… ë°©í–¥ ë° ì‹ ë¢°ë„ ê²°ì •
            # ë°©í–¥ ê²°ì • (ë‹¤ìˆ˜ê²°)
            up_count = direction_signals.count("UP")
            down_count = direction_signals.count("DOWN")
            sideways_count = direction_signals.count("SIDEWAYS")
            
            if up_count > down_count and up_count > sideways_count:
                predicted_direction = "UP"
            elif down_count > up_count and down_count > sideways_count:
                predicted_direction = "DOWN"
            else:
                predicted_direction = "SIDEWAYS"
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            base_confidence = np.mean(confidence_factors)
            
            # ì‹ í˜¸ ì¼ì¹˜ë„ ë³´ë„ˆìŠ¤
            max_signal_count = max(up_count, down_count, sideways_count)
            signal_consistency = max_signal_count / len(direction_signals)
            consistency_bonus = (signal_consistency - 0.5) * 0.4  # 0.5ëŠ” ëœë¤, 1.0ì€ ì™„ì „ ì¼ì¹˜
            
            # ë¶ˆí™•ì‹¤ì„± í˜ë„í‹° ì ìš©
            final_confidence = base_confidence + consistency_bonus - uncertainty_penalty
            final_confidence = max(0.1, min(0.95, final_confidence))  # 0.1~0.95 ë²”ìœ„ë¡œ ì œí•œ
            
            print(f"=== Advanced TST Prediction Analysis ===")
            print(f"RL State: mean={rl_state_mean:.4f}, std={rl_state_std:.4f}")
            print(f"Price Change Rate: {price_change_rate*100:.2f}%")
            print(f"Direction Signals: {direction_signals}")
            print(f"Signal Consistency: {signal_consistency:.2f}")
            print(f"MC Uncertainty: RL={mc_rl_mean_var:.6f}, Price={mc_price_var:.6f}")
            print(f"Uncertainty Penalty: {uncertainty_penalty:.3f}")
            print(f"Base Confidence: {base_confidence:.3f}")
            print(f"Final Confidence: {final_confidence:.3f}")
            print(f"Predicted Direction: {predicted_direction}")
            
            return {
                "predicted_direction": predicted_direction,
                "confidence": final_confidence,
                "rl_state": rl_state_numpy,
                "rl_state_mean": rl_state_mean,
                "rl_state_std": rl_state_std,
                "price_change_rate": price_change_rate,
                "signal_consistency": signal_consistency,
                "uncertainty_penalty": uncertainty_penalty,
                "mc_variance": {"rl": mc_rl_mean_var, "price": mc_price_var}
            }
        
    except Exception as e:
        print(f"Error in TST prediction: {e}")
        import traceback
        traceback.print_exc()
        return {"predicted_direction": "UNKNOWN", "confidence": 0.0, "rl_state": None}

def construct_rl_state_vector(current_state_vars: dict, technical_data: pd.DataFrame, 
                                daily_sentiment: pd.Series, tst_prediction: dict):
    """Constructs the state vector for the RL agent.
    Combines various pieces of information into a format suitable for the agent.
    Returns: A dictionary representing the state.
    """
    print("\n--- 6. Constructing State Vector for RL Agent ---")
    
    # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ (ì»¬ëŸ¼ëª… ì²´í¬)
    if not technical_data.empty:
        # 'Close' ë˜ëŠ” 'close' ì»¬ëŸ¼ ì°¾ê¸°
        if 'Close' in technical_data.columns:
            current_price = technical_data['Close'].iloc[-1]
        elif 'close' in technical_data.columns:
            current_price = technical_data['close'].iloc[-1]
        else:
            print(f"Warning: No Close/close column found. Available columns: {technical_data.columns.tolist()}")
            current_price = None
    else:
        current_price = None
        
    latest_sentiment = daily_sentiment.iloc[-1] if not daily_sentiment.empty else 0.0

    # TST RL State ì‚¬ìš© (ì‹¤ì œ 256ì°¨ì› ë²¡í„°)
    tst_rl_state = tst_prediction.get("rl_state")
    
    state_vector = {
        "ticker": current_state_vars["ticker"],
        "current_price": current_price,
        "market_sentiment_score": latest_sentiment,
        "tst_predicted_direction": tst_prediction.get("predicted_direction"),
        "tst_confidence": tst_prediction.get("confidence"),
        "tst_rl_state": tst_rl_state,  # 256ì°¨ì› RL state ë²¡í„°
        "tst_rl_state_mean": tst_prediction.get("rl_state_mean"),
        "tst_rl_state_std": tst_prediction.get("rl_state_std"),
        "has_shares": current_state_vars["holdings_info"]["has_shares"],
        "num_shares": current_state_vars["holdings_info"]["num_shares"],
        "avg_purchase_price": current_state_vars["holdings_info"]["avg_price"],
        "available_cash": current_state_vars["available_cash"],
        "user_action_preference": current_state_vars["user_intention"],
        # RL ì—ì´ì „íŠ¸ê°€ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœë¡œ ì¶”ê°€ ë§¤í•‘
        "cash": current_state_vars["available_cash"],  # bullet -> cash
        "shares": current_state_vars["holdings_info"]["num_shares"],  # num_shares -> shares
        "price": current_price  # current_priceì˜ ë³„ì¹­
    }
    
    print(f"RL State Vector constructed:")
    print(f"  Current price: {current_price}")
    print(f"  Sentiment: {latest_sentiment:.3f}")
    print(f"  TST RL State: {type(tst_rl_state)} shape={tst_rl_state.shape if tst_rl_state is not None else None}")
    print(f"  TST Direction: {tst_prediction.get('predicted_direction')}")
    print(f"  TST Confidence: {tst_prediction.get('confidence'):.3f}")
    print(f"  Portfolio Info: Cash=${state_vector['cash']:.2f}, Shares={state_vector['shares']}, Avg Price=${state_vector['avg_purchase_price']:.2f}")
    
    return state_vector

def get_action_from_rl_agent(state_vector: dict, agent_choice: str):
    """Gets the trading action from the chosen RL agent.
    Uses: ppo_agent.py or sac_agent.py (mocked here)
    Returns: A dictionary with the agent's action and reasoning.
    """
    print(f"\n--- 7. Getting Action from RL Agent ({agent_choice}) ---")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    state_dim = 259 # 256 for TST state + 3 for portfolio info (cash_ratio, stock_ratio, portfolio_value_normalized)
    
    agent = load_latest_rl_agent(agent_choice, RL_MODEL_DIR, device, state_dim)

    if agent is None:
        print(f"Could not load agent {agent_choice}. Defaulting to HOLD.")
        return {"action": "HOLD", "reason": f"Failed to load {agent_choice} agent."}

    if not state_vector.get("current_price"):
         print("Skipping RL action due to missing current price in state vector.")
         return {"action": "HOLD", "reason": "Insufficient data for RL decision (missing price)"}
    
    if state_vector.get("tst_rl_state") is None:
        print("Skipping RL action due to missing TST RL state in state vector.")
        return {"action": "HOLD", "reason": "Insufficient data for RL decision (missing TST state)"}


    try:
        # The agent's predict_action should handle the state_vector directly
        rl_action_decision = agent.predict_action(state_vector)
        print(f"RL Agent ({agent_choice}) Decision: {rl_action_decision}")
        return rl_action_decision
    except Exception as e:
        print(f"Error during RL agent prediction ({agent_choice}): {e}")
        import traceback
        traceback.print_exc()
        return {"action": "HOLD", "reason": f"Error during {agent_choice} prediction: {e}"}

def generate_final_recommendation(tst_prediction: dict, rl_decision: dict, ticker: str):
    """Generates the final trading recommendation for the user.
    Combines TST insights and RL agent action into human-readable advice.
    Returns: A string with the recommendation.
    """
    print("\n--- 8. Generating Enhanced Trading Recommendation ---")
    
    # ì‹ ë¢°ë„ ë ˆë²¨ ë¶„ë¥˜
    confidence = tst_prediction.get('confidence', 0)
    if confidence >= 0.7:
        confidence_level = "HIGH"
        confidence_emoji = "ğŸ”¥"
    elif confidence >= 0.5:
        confidence_level = "MEDIUM"
        confidence_emoji = "âš–ï¸"
    else:
        confidence_level = "LOW"
        confidence_emoji = "âš ï¸"
    
    recommendation = f"=== ğŸ“Š Advanced Trading Recommendation for {ticker} ===\n\n"
    
    # TST ëª¨ë¸ ë¶„ì„
    recommendation += f"ğŸ¤– **TST Model Analysis**\n"
    recommendation += f"   Direction: {tst_prediction.get('predicted_direction', 'N/A')}\n"
    recommendation += f"   Confidence: {confidence*100:.1f}% ({confidence_level}) {confidence_emoji}\n"
    
    # ìƒì„¸ ë¶„ì„ ì •ë³´
    if tst_prediction.get('price_change_rate') is not None:
        price_change = tst_prediction.get('price_change_rate', 0) * 100
        recommendation += f"   Expected Price Movement: {price_change:+.2f}%\n"
    
    if tst_prediction.get('signal_consistency') is not None:
        consistency = tst_prediction.get('signal_consistency', 0) * 100
        recommendation += f"   Signal Consistency: {consistency:.1f}%\n"
    
    if tst_prediction.get('uncertainty_penalty') is not None:
        uncertainty = tst_prediction.get('uncertainty_penalty', 0)
        recommendation += f"   Model Uncertainty: {uncertainty:.3f}\n"
    
    # RL State ì •ë³´
    if tst_prediction.get('rl_state') is not None:
        recommendation += f"   RL State: Mean={tst_prediction.get('rl_state_mean', 0):.4f}, Std={tst_prediction.get('rl_state_std', 0):.4f}\n"
    
    recommendation += f"\nğŸ¯ **RL Agent Decision**\n"
    rl_action = rl_decision.get('action', 'N/A')
    recommendation += f"   Action: {rl_action}\n"
    recommendation += f"   Reasoning: {rl_decision.get('reason', 'N/A')}\n"

    actual_current_price = rl_decision.get('target_price') # This is the current price at the time of RL decision
    suggested_price_text = ""

    if actual_current_price is not None:
        if rl_action == "BUY":
            price_change_rate = tst_prediction.get('price_change_rate', 0)
            tst_direction = tst_prediction.get('predicted_direction')
            tst_confidence = tst_prediction.get('confidence', 0)
            
            if tst_direction == "UP" and tst_confidence >= 0.6:
                suggested_price_text = f"í˜„ì¬ê°€(${actual_current_price:.2f}) ë˜ëŠ” ì•½ê°„ ë‚®ì€ ê°€ê²©ì—ì„œ ë¶„í•  ë§¤ìˆ˜ë¥¼ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            elif tst_direction == "UP" and tst_confidence >= 0.4:
                 suggested_price_text = f"í˜„ì¬ê°€(${actual_current_price:.2f}) ê·¼ì²˜ì—ì„œ ë§¤ìˆ˜ë¥¼ ê³ ë ¤í•˜ë˜, TST ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ì¤‘ê°„ ìˆ˜ì¤€ì„ì„ ì°¸ê³ í•˜ì„¸ìš”."
            else:
                suggested_price_text = f"í˜„ì¬ ì‹œì¥ê°€(ì•½ ${actual_current_price:.2f})ì— ë§¤ìˆ˜ë¥¼ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. TST ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë‚®ê±°ë‚˜ ë°©í–¥ì„±ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            recommendation += f"   ì œì•ˆ ì§„ì… ì „ëµ: {suggested_price_text}\n"

        elif rl_action == "SELL":
            price_change_rate = tst_prediction.get('price_change_rate', 0)
            tst_direction = tst_prediction.get('predicted_direction')
            tst_confidence = tst_prediction.get('confidence', 0)

            if tst_direction == "DOWN" and tst_confidence >= 0.6:
                suggested_price_text = f"í˜„ì¬ê°€(${actual_current_price:.2f}) ë˜ëŠ” ì•½ê°„ ë†’ì€ ê°€ê²©ì—ì„œ ì‹ ì†í•œ ë§¤ë„ë¥¼ ê³ ë ¤í•˜ì„¸ìš”."
            elif tst_direction == "DOWN" and tst_confidence >= 0.4:
                suggested_price_text = f"í˜„ì¬ê°€(${actual_current_price:.2f}) ê·¼ì²˜ì—ì„œ ë§¤ë„ë¥¼ ê³ ë ¤í•˜ë˜, TST ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ì¤‘ê°„ ìˆ˜ì¤€ì„ì„ ì°¸ê³ í•˜ì„¸ìš”."
            elif tst_direction == "UP" and price_change_rate > 0.03 and tst_confidence > 0.3: # TST expects decent rise with some confidence
                 upside_target_low = actual_current_price * (1 + price_change_rate * 0.3) # Capture a smaller portion
                 upside_target_high = actual_current_price * (1 + price_change_rate * 0.6) # Capture a larger portion
                 suggested_price_text = (f"TST ëª¨ë¸ì€ ë‹¨ê¸° ìƒìŠ¹(${price_change_rate*100:+.1f}%)ì„ ì˜ˆìƒí•©ë‹ˆë‹¤. "
                                       f"ì ì¬ì  ìƒìŠ¹ë¶„ì„ ì¼ë¶€ ê³ ë ¤í•˜ì—¬ í˜„ì¬ê°€(${actual_current_price:.2f})ë³´ë‹¤ ë†’ì€ ì§€ì •ê°€ ë§¤ë„(ì˜ˆ: ${upside_target_low:.2f} ~ ${upside_target_high:.2f})ë¥¼ ê³ ë ¤í•˜ê±°ë‚˜, "
                                       f"ì¦‰ê°ì ì¸ ìœ„í—˜ ê´€ë¦¬ë¥¼ ì›í•˜ì‹œë©´ ì‹œì¥ê°€(${actual_current_price:.2f}) ë§¤ë„ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
            else: # Default sell at current market, or TST has low confidence / conflicting signals
                suggested_price_text = f"í˜„ì¬ ì‹œì¥ê°€(ì•½ ${actual_current_price:.2f})ì— ë§¤ë„ë¥¼ ê³ ë ¤í•˜ì„¸ìš”. TST ì˜ˆì¸¡ê³¼ RL ì—ì´ì „íŠ¸ ê²°ì •ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            recommendation += f"   ì œì•ˆ ì²­ì‚° ì „ëµ: {suggested_price_text}\n"
    
    # ì¢…í•© ì¡°ì–¸
    recommendation += f"\nğŸ’¡ **Investment Advice**\n"
    
    action = rl_decision.get('action', 'HOLD')
    if action == "BUY" and confidence >= 0.6:
        recommendation += f"   âœ… Strong BUY signal with good confidence\n"
    elif action == "BUY" and confidence < 0.6:
        recommendation += f"   âš ï¸ BUY signal but with limited confidence - consider smaller position\n"
    elif action == "SELL" and confidence >= 0.6:
        recommendation += f"   ğŸ”´ Strong SELL signal with good confidence\n"
    elif action == "SELL" and confidence < 0.6:
        recommendation += f"   âš ï¸ SELL signal but with limited confidence - consider partial exit\n"
    else:
        recommendation += f"   â¸ï¸ HOLD recommended - wait for clearer signals\n"
    
    # ë¦¬ìŠ¤í¬ ê²½ê³ 
    if confidence < 0.4:
        recommendation += f"   âš ï¸ **HIGH UNCERTAINTY**: Consider waiting for better signals\n"
    elif tst_prediction.get('uncertainty_penalty', 0) > 0.2:
        recommendation += f"   ğŸ“‰ **MODEL UNCERTAINTY**: Multiple signals show high variance\n"
    
    recommendation += f"\n" + "="*60
    
    print(recommendation)
    return recommendation

# --- Main Execution Flow --- 
def run_trading_bot():
    """Main function to run the trading bot logic.
    """
    try:
        # 1. Get user input
        user_input = get_user_input()
        
        # 2. Initialize core state variables from user input
        current_state = initialize_state_variables(user_input)
        ticker = current_state["ticker"]
        days_to_analyze = 7 # As per specification for news and TA

        # 3. Collect real-time TA data
        current_utc_time = datetime.now(timezone.utc)
        print(f"\n=== Starting Real-time Data Collection for {ticker} ===")
        
        ta_df = collect_realtime_ta_data(
            ticker=ticker,
            business_days=days_to_analyze,
            lookback_period=TA_LOOKBACK_PERIOD
        )
        
        if ta_df.empty:
            print("âŒ Failed to collect TA data. Aborting.")
            return
        
        # 4. Collect real-time news sentiment data
        news_df = collect_realtime_news_data(
            ticker=ticker,
            analysis_days=days_to_analyze
        )
        
        # ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê¸°ì¡´ í˜•ì‹ì— ë§ê²Œ ë³€í™˜
        if not news_df.empty:
            # combined_score ê³„ì‚°
            news_df['combined_score'] = (
                news_df['avg_sentiment_positive'] - news_df['avg_sentiment_negative'] +
                news_df['weekend_effect_positive'] - news_df['weekend_effect_negative']
            )
            daily_sentiment_scores = news_df['combined_score']
        else:
            # ë¹ˆ ì‹œë¦¬ì¦ˆ ìƒì„±
            daily_sentiment_scores = pd.Series(dtype=float, name='combined_score')
        
        # TA ë°ì´í„°ë¥¼ ê¸°ì¡´ í˜•ì‹ì— ë§ê²Œ ë³€í™˜
        ta_df['Date'] = pd.to_datetime(ta_df['Date'])
        ta_df.set_index('Date', inplace=True)
        
        # TST ëª¨ë¸ì„ ìœ„í•œ ì „ì²´ ë°ì´í„° ì¤€ë¹„ (60ì¼ ì»¨í…ìŠ¤íŠ¸ í•„ìš”)
        full_technical_data = ta_df.copy()
        full_technical_data.index = pd.to_datetime(full_technical_data.index).date
        full_technical_data.index.name = 'Date'
        full_technical_data.fillna(0.0, inplace=True)
        
        # RL State êµ¬ì„±ì„ ìœ„í•œ ìµœê·¼ 7ì¼ ë°ì´í„°
        relevant_dates = []
        current_d = current_utc_time.date() - timedelta(days=1)
        while len(relevant_dates) < days_to_analyze:
            if is_us_business_day(current_d):
                relevant_dates.append(current_d)
            current_d -= timedelta(days=1)
        relevant_dates.sort()
        
        recent_technical_data = ta_df.reindex(pd.to_datetime(relevant_dates))
        recent_technical_data.index = pd.to_datetime(recent_technical_data.index).date
        recent_technical_data.index.name = 'Date'
        recent_technical_data.fillna(0.0, inplace=True)
        
        print(f"âœ… Final data prepared:")
        print(f"  Full TA data (for TST): {full_technical_data.shape}")
        print(f"  Recent TA data (for RL): {recent_technical_data.shape}")
        print(f"  News sentiment: {len(daily_sentiment_scores)} entries")
        
        # 5. Predict price movement using TST model (ì „ì²´ ë°ì´í„° ì‚¬ìš©)
        tst_price_prediction = predict_price_with_tst_model(full_technical_data, daily_sentiment_scores, ticker)
        
        # 6. Construct the state vector for the RL agent (ìµœê·¼ ë°ì´í„° ì‚¬ìš©)
        rl_state = construct_rl_state_vector(current_state, recent_technical_data, daily_sentiment_scores, tst_price_prediction)
        
        # 7. Get action from the chosen RL agent
        rl_action = get_action_from_rl_agent(rl_state, current_state["chosen_agent"])
        
        # 8. Generate final trading recommendation
        final_recommendation_message = generate_final_recommendation(tst_price_prediction, rl_action, ticker)
        
        print("\n=== Trading Bot Cycle Completed Successfully ===")
        print(f"âœ… Real-time data collection: TA + News")
        print(f"âœ… TST Model prediction: RL State generated")
        print(f"âœ… RL Agent decision: {rl_action.get('action')}")
        print(f"âœ… Final recommendation provided")

    except ValueError as ve:
        print(f"Input Error: {ve}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        # In a real application, add more detailed error logging here

if __name__ == "__main__":
    run_trading_bot() 